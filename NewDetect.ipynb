{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaiKhoa0101/MachineLearning/blob/main/NewDetect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gblnsVP8nHTC",
        "outputId": "113a6018-8230-4c9f-a06e-d01b8d7d1703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: mediapipe 0.10.18\n",
            "Uninstalling mediapipe-0.10.18:\n",
            "  Successfully uninstalled mediapipe-0.10.18\n",
            "Files removed: 6\n",
            "Collecting mediapipe==0.10.18\n",
            "  Downloading mediapipe-0.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (0.7.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (0.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.18) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.18) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.18) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.18) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.18) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.18) (1.17.0)\n",
            "Downloading mediapipe-0.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.10.18\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.18)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall mediapipe -y\n",
        "!pip cache purge\n",
        "!pip install mediapipe==0.10.18\n",
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN-hjxOSnKoN",
        "outputId": "8a6f7a8c-95b7-435b-fbef-3f21f2c6929e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: flask>=0.9 in /usr/local/lib/python3.12/dist-packages (from flask-cors) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.12/dist-packages (from flask-cors) (3.1.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "pip install flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SszBbQuGm3Ll",
        "outputId": "32585405-97f5-4152-b952-b841d12c412d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "SIGN LANGUAGE DETECTION API V6\n",
            "======================================================================\n",
            "Cleaned up 0 old jobs\n",
            "üåç PUBLIC URL: NgrokTunnel: \"https://lorriane-noncongregative-benson.ngrok-free.dev\" -> \"http://localhost:5000\"\n",
            "üè† Local URL: http://localhost:5000\n",
            "üìÅ Results directory: api_results\n",
            "\n",
            "üìå Endpoints:\n",
            "  POST /api/detect              - Submit video URL\n",
            "  GET  /api/job/<id>            - Check job status\n",
            "  GET  /api/job/<id>/download   - Download results\n",
            "  GET  /api/job/<id>/preview    - Preview results\n",
            "  GET  /api/jobs                - List all jobs\n",
            "  DELETE /api/job/<id>          - Delete job\n",
            "  GET  /api/health              - Health check\n",
            "======================================================================\n",
            "\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "COMPLETE SIGN LANGUAGE DETECTION API WITH AUTO-TRIM\n",
        "====================================================\n",
        "T√≠ch h·ª£p ƒë·∫ßy ƒë·ªß: Motion Retargeting + Video Trimming + Flask API\n",
        "\"\"\"\n",
        "\n",
        "# !pip install -q pyngrok flask flask-cors opencv-python mediapipe numpy\n",
        "\n",
        "## API\n",
        "!pip install -q pyngrok flask flask-cors\n",
        "\n",
        "# api_sign_language.py\n",
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import threading\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "from flask_cors import CORS\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import threading\n",
        "from datetime import datetime\n",
        "from math import sqrt, atan2, degrees, acos\n",
        "from typing import Dict, Optional, Tuple\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def is_url(path: str) -> bool:\n",
        "    \"\"\"Ki·ªÉm tra xem ƒë∆∞·ªùng d·∫´n c√≥ ph·∫£i l√† URL kh√¥ng\"\"\"\n",
        "    return path.startswith(('http://', 'https://'))\n",
        "\n",
        "def download_video(url: str) -> str:\n",
        "    \"\"\"Download video t·ª´ URL v√† l∆∞u v√†o file t·∫°m\"\"\"\n",
        "    print(f\"üåê Downloading video from URL: {url}\")\n",
        "    try:\n",
        "        temp_dir = tempfile.gettempdir()\n",
        "        temp_filename = f\"video_{os.path.basename(url).split('?')[0]}\"\n",
        "        temp_path = os.path.join(temp_dir, temp_filename)\n",
        "\n",
        "        if not temp_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
        "            temp_path += '.mp4'\n",
        "\n",
        "        urllib.request.urlretrieve(url, temp_path)\n",
        "        print(f\"‚úÖ Video downloaded to: {temp_path}\")\n",
        "        return temp_path\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error downloading video: {e}\")\n",
        "        raise\n",
        "\n",
        "# ============================================================================\n",
        "# RIG CONFIGURATION\n",
        "# ============================================================================\n",
        "class RigConfiguration:\n",
        "    \"\"\"C·∫•u h√¨nh √°nh x·∫° gi·ªØa g√≥c v·∫≠t l√Ω v√† tr·ª•c x∆∞∆°ng c·ªßa Model 3D\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # UPPER ARM\n",
        "        self.UPPERARM_L = {\n",
        "            \"y\": {\"axis\": \"y\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"z\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"x\": {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.UPPERARM_R = {\n",
        "            \"y\": {\"axis\": \"y\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"z\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"x\": {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "        # LOWER ARM\n",
        "        self.LOWERARM_L = {\n",
        "            \"bend\": {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "            \"rotation\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.LOWERARM_R = {\n",
        "            \"bend\": {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "            \"rotation\": {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "        # WRIST/HAND - ‚úÖ C·∫¨P NH·∫¨T ƒê·∫¶Y ƒê·ª¶ 3-DOF\n",
        "        self.HAND_L = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},   # C√∫i/ng·ª≠a c·ªï tay\n",
        "            \"yaw\": {\"axis\": \"y\", \"scale\": 0.5, \"offset\": 0},     # Quay tr√°i/ph·∫£i\n",
        "            \"roll\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}     # Xoay (pronation/supination)\n",
        "        }\n",
        "        self.HAND_R = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\": {\"axis\": \"y\", \"scale\": 0.5, \"offset\": 0},\n",
        "            \"roll\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "        # FINGERS\n",
        "        self.FINGER_CONFIG = {\"bend\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0}}\n",
        "\n",
        "        # HEAD & NECK\n",
        "        self.HEAD = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"roll\": {\"axis\": \"y\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.NECK = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 0.5, \"offset\": 0},\n",
        "            \"yaw\": {\"axis\": \"x\", \"scale\": 0.5, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "        # SPINE\n",
        "        self.SPINE = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "    def apply_mapping(self, physical_angles: Dict, config: Dict) -> Dict:\n",
        "        \"\"\"√Åp d·ª•ng configuration ƒë·ªÉ chuy·ªÉn g√≥c v·∫≠t l√Ω th√†nh output Model\"\"\"\n",
        "        result = {\"x\": 0, \"y\": 0, \"z\": 0}\n",
        "        for angle_type, angle_value in physical_angles.items():\n",
        "            if angle_type in config:\n",
        "                mapping = config[angle_type]\n",
        "                axis = mapping[\"axis\"]\n",
        "                scale = mapping[\"scale\"]\n",
        "                offset = mapping[\"offset\"]\n",
        "                result[axis] = round(angle_value * scale + offset, 2)\n",
        "        return result\n",
        "\n",
        "# ============================================================================\n",
        "# PHYSICAL ANGLE CALCULATOR\n",
        "# ============================================================================\n",
        "\n",
        "class PhysicalAngleCalculator:\n",
        "    \"\"\"T√≠nh g√≥c v·∫≠t l√Ω th·ª±c t·∫ø t·ª´ MediaPipe landmarks\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_elbow_bend(shoulder, elbow, wrist) -> float:\n",
        "        \"\"\"T√≠nh g√≥c g·∫≠p khu·ª∑u tay (Law of Cosines)\"\"\"\n",
        "        a = np.linalg.norm([elbow.x - shoulder.x, elbow.y - shoulder.y, elbow.z - shoulder.z])\n",
        "        b = np.linalg.norm([wrist.x - elbow.x, wrist.y - elbow.y, wrist.z - elbow.z])\n",
        "        c = np.linalg.norm([wrist.x - shoulder.x, wrist.y - shoulder.y, wrist.z - shoulder.z])\n",
        "\n",
        "        cos_angle = (a*a + b*b - c*c) / (2 * a * b + 1e-6)\n",
        "        cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
        "        angle = degrees(acos(cos_angle))\n",
        "        return angle\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_forearm_rotation(shoulder, elbow, wrist) -> float:\n",
        "        \"\"\"T√≠nh g√≥c xoay c·∫≥ng tay\"\"\"\n",
        "        upper_arm = np.array([\n",
        "            elbow.x - shoulder.x,\n",
        "            elbow.y - shoulder.y,\n",
        "            elbow.z - shoulder.z\n",
        "        ])\n",
        "        upper_arm = upper_arm / (np.linalg.norm(upper_arm) + 1e-6)\n",
        "\n",
        "        forearm = np.array([\n",
        "            wrist.x - elbow.x,\n",
        "            wrist.y - elbow.y,\n",
        "            wrist.z - elbow.z\n",
        "        ])\n",
        "        forearm = forearm / (np.linalg.norm(forearm) + 1e-6)\n",
        "\n",
        "        projection = np.dot(forearm, upper_arm) * upper_arm\n",
        "        perpendicular = forearm - projection\n",
        "        perp_length = np.linalg.norm(perpendicular) + 1e-6\n",
        "        perpendicular = perpendicular / perp_length\n",
        "\n",
        "        reference = np.array([0, 1, 0])\n",
        "        ref_proj = reference - np.dot(reference, upper_arm) * upper_arm\n",
        "        ref_length = np.linalg.norm(ref_proj) + 1e-6\n",
        "        ref_proj = ref_proj / ref_length\n",
        "\n",
        "        cos_angle = np.clip(np.dot(perpendicular, ref_proj), -1.0, 1.0)\n",
        "        rotation_angle = degrees(acos(cos_angle))\n",
        "\n",
        "        cross = np.cross(ref_proj, perpendicular)\n",
        "        if np.dot(cross, upper_arm) < 0:\n",
        "            rotation_angle = -rotation_angle\n",
        "\n",
        "        return round(rotation_angle, 2)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_wrist_orientation(shoulder, elbow, wrist, hand_landmarks) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        ‚úÖ T√çNH G√ìC C·ªî TAY - SIMPLE Y-AXIS ANGLE\n",
        "\n",
        "        Ch·ªâ d√πng Y component ƒë·ªÉ t√≠nh flexion/extension\n",
        "        \"\"\"\n",
        "        if hand_landmarks is None:\n",
        "            return {\"pitch\": 0.0, \"yaw\": 0.0, \"roll\": 0.0}\n",
        "\n",
        "        wrist_lm = hand_landmarks.landmark[0]     # Wrist\n",
        "        middle_mcp = hand_landmarks.landmark[9]   # Middle base\n",
        "\n",
        "        # Ch·ªâ quan t√¢m ƒë·∫øn Y difference (vertical)\n",
        "        dy = middle_mcp.y - wrist_lm.y\n",
        "\n",
        "        # T√≠nh g√≥c t·ª´ Y component\n",
        "        # Trong MediaPipe hand: Y tƒÉng = xu·ªëng d∆∞·ªõi\n",
        "        # dy > 0 = hand pointing down (flexion)\n",
        "        # dy < 0 = hand pointing up (extension)\n",
        "\n",
        "        # Scale xu·ªëng ƒë·ªÉ c√≥ g√≥c h·ª£p l√Ω (d·ª±a v√†o th·ª±c nghi·ªám)\n",
        "        pitch = dy * 100  # Adjust multiplier as needed\n",
        "\n",
        "        # Clamp\n",
        "        pitch = np.clip(pitch, -45, 90)\n",
        "\n",
        "        return {\n",
        "            \"pitch\": round(pitch, 2),\n",
        "            \"yaw\": 0.0,\n",
        "            \"roll\": 0.0\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_arm_orientation(shoulder, elbow, wrist=None) -> Dict[str, float]:\n",
        "        \"\"\"T√≠nh h∆∞·ªõng c·ªßa c√°nh tay theo Euler XYZ\"\"\"\n",
        "        dx = elbow.x - shoulder.x\n",
        "        dy = elbow.y - shoulder.y\n",
        "        dz = elbow.z - shoulder.z\n",
        "\n",
        "        length = sqrt(dx*dx + dy*dy + dz*dz)\n",
        "        dx, dy, dz = dx/length, dy/length, dz/length\n",
        "\n",
        "        y_angle = degrees(dy)\n",
        "        horizontal_dist = sqrt(dx*dx + dz*dz)\n",
        "        z_angle = degrees(np.arcsin(dz / horizontal_dist)) + 15\n",
        "        x_angle = degrees(dx)*-2\n",
        "\n",
        "        if wrist is not None:\n",
        "          wx = wrist.x - elbow.x\n",
        "          wy = wrist.y - elbow.y\n",
        "          wz = wrist.z - elbow.z\n",
        "\n",
        "          arm_axis = np.array([dx, dy, dz])\n",
        "          wrist_vec = np.array([wx, wy, wz])\n",
        "\n",
        "          projection = np.dot(wrist_vec, arm_axis) * arm_axis\n",
        "          perpendicular = wrist_vec - projection\n",
        "\n",
        "          perp_length = np.linalg.norm(perpendicular) + 1e-6\n",
        "          perpendicular = perpendicular / perp_length\n",
        "\n",
        "          ref_vec = np.array([0, -1, 0])\n",
        "          ref_proj = ref_vec - np.dot(ref_vec, arm_axis) * arm_axis\n",
        "          ref_length = np.linalg.norm(ref_proj) + 1e-6\n",
        "          ref_proj = ref_proj / ref_length\n",
        "\n",
        "          cos_angle = np.clip(np.dot(perpendicular, ref_proj), -1.0, 1.0)\n",
        "          x_angle = degrees(acos(cos_angle))\n",
        "\n",
        "          cross = np.cross(ref_proj, perpendicular)\n",
        "          if np.dot(cross, arm_axis) < 0:\n",
        "              x_angle = -x_angle\n",
        "\n",
        "        return {\n",
        "            \"y\": round(y_angle, 2),\n",
        "            \"z\": round(z_angle, 2),\n",
        "            \"x\": round(x_angle, 2)\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_finger_bend(landmarks, finger_ids) -> float:\n",
        "        \"\"\"T√≠nh g√≥c g·∫≠p trung b√¨nh c·ªßa ng√≥n tay\"\"\"\n",
        "        total_angle = 0\n",
        "        count = 0\n",
        "\n",
        "        for i in range(1, len(finger_ids)-1):\n",
        "            p1 = landmarks[finger_ids[i-1]]\n",
        "            p2 = landmarks[finger_ids[i]]\n",
        "            p3 = landmarks[finger_ids[i+1]]\n",
        "\n",
        "            a = np.linalg.norm([p2.x - p1.x, p2.y - p1.y, p2.z - p1.z])\n",
        "            b = np.linalg.norm([p3.x - p2.x, p3.y - p2.y, p3.z - p2.z])\n",
        "            c = np.linalg.norm([p3.x - p1.x, p3.y - p1.y, p3.z - p1.z])\n",
        "\n",
        "            cos_angle = (a*a + b*b - c*c) / (2 * a * b + 1e-6)\n",
        "            cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
        "\n",
        "            angle = degrees(acos(cos_angle))\n",
        "            total_angle += (180 - angle)\n",
        "            count += 1\n",
        "\n",
        "        avg_angle = total_angle / count if count > 0 else 0\n",
        "        return round(avg_angle, 2)\n",
        "\n",
        "# ============================================================================\n",
        "# GESTURE DETECTOR\n",
        "# ============================================================================\n",
        "\n",
        "class GestureDetector:\n",
        "    \"\"\"Detector s·ª≠ d·ª•ng Physical Calculation + Rig Configuration\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.calc = PhysicalAngleCalculator()\n",
        "        self.rig = RigConfiguration()\n",
        "\n",
        "    def detect_arm(self, pose_lm, hand_landmarks, side='left') -> Dict:\n",
        "        \"\"\"Ph√°t hi·ªán v√† chuy·ªÉn ƒë·ªïi g√≥c c√°nh tay - ‚úÖ ƒê√É C√ì WRIST ORIENTATION\"\"\"\n",
        "        if side == 'left':\n",
        "            shoulder, elbow, wrist = pose_lm[11], pose_lm[13], pose_lm[15]\n",
        "            suffix = 'l'\n",
        "            upperarm_config = self.rig.UPPERARM_L\n",
        "            lowerarm_config = self.rig.LOWERARM_L\n",
        "            hand_config = self.rig.HAND_L\n",
        "        else:\n",
        "            shoulder, elbow, wrist = pose_lm[12], pose_lm[14], pose_lm[16]\n",
        "            suffix = 'r'\n",
        "            upperarm_config = self.rig.UPPERARM_R\n",
        "            lowerarm_config = self.rig.LOWERARM_R\n",
        "            hand_config = self.rig.HAND_R\n",
        "\n",
        "        # Calculate angles\n",
        "        upperarm_angles = self.calc.calculate_arm_orientation(shoulder, elbow)\n",
        "\n",
        "        if hand_landmarks is None:\n",
        "            elbow_bend = 0\n",
        "            forearm_rotation = 0\n",
        "            wrist_angles = {\"pitch\": 0, \"yaw\": 0, \"roll\": 0}\n",
        "        else:\n",
        "            elbow_bend = self.calc.calculate_elbow_bend(shoulder, elbow, wrist)\n",
        "            forearm_rotation = self.calc.calculate_forearm_rotation(shoulder, elbow, wrist)\n",
        "            # ‚úÖ FIXED: Truy·ªÅn ƒë·∫ßy ƒë·ªß shoulder, elbow, wrist\n",
        "            wrist_angles = self.calc.calculate_wrist_orientation(\n",
        "                shoulder, elbow, wrist, hand_landmarks\n",
        "            )\n",
        "        # Apply rig configuration\n",
        "        upperarm_result = self.rig.apply_mapping(upperarm_angles, upperarm_config)\n",
        "\n",
        "        lowerarm_result = self.rig.apply_mapping({\n",
        "            \"bend\": elbow_bend,\n",
        "            \"rotation\": forearm_rotation\n",
        "        }, lowerarm_config)\n",
        "\n",
        "        # ‚úÖ MAP WRIST ORIENTATION\n",
        "        hand_result = self.rig.apply_mapping(wrist_angles, hand_config)\n",
        "\n",
        "        output = {\n",
        "            f\"shoulder_{suffix}\": f\"shoulder_{suffix}(x=0, y=0, z=0)\",\n",
        "            f\"upperarm_{suffix}\": f\"upperarm_{suffix}(x={upperarm_result['x']*2 if suffix=='r' else upperarm_result['x']*-2}, y={upperarm_result['y']}, z={upperarm_result['z']})\",\n",
        "            f\"lowerarm_{suffix}\": f\"lowerarm_{suffix}(x={lowerarm_result['x']}, y={lowerarm_result['y']}, z={lowerarm_result['z']})\",\n",
        "            # ‚úÖ WRIST ORIENTATION ƒê·∫¶Y ƒê·ª¶\n",
        "            f\"hand_{suffix}\": f\"hand_{suffix}(x={hand_result['x']}, y={hand_result['y']}, z={hand_result['z']})\"\n",
        "        }\n",
        "\n",
        "        # Fingers\n",
        "        if hand_landmarks is None:\n",
        "            for finger in ['thumb', 'index', 'middle', 'ring', 'pinky']:\n",
        "                output[f\"{finger}_{suffix}\"] = self._default_finger(finger, suffix)\n",
        "        else:\n",
        "            hand_lm = hand_landmarks.landmark\n",
        "\n",
        "            finger_ids = {\n",
        "                \"thumb\": [1, 2, 3, 4],\n",
        "                \"index\": [5, 6, 7, 8],\n",
        "                \"middle\": [9, 10, 11, 12],\n",
        "                \"ring\": [13, 14, 15, 16],\n",
        "                \"pinky\": [17, 18, 19, 20]\n",
        "            }\n",
        "\n",
        "            for fname, ids in finger_ids.items():\n",
        "                bend = self.calc.calculate_finger_bend(hand_lm, ids)\n",
        "                finger_result = self.rig.apply_mapping({\"bend\": bend}, self.rig.FINGER_CONFIG)\n",
        "                output[f\"{fname}_{suffix}\"] = self._format_finger(fname, suffix, finger_result['z'])\n",
        "\n",
        "        return output\n",
        "\n",
        "    def detect_head_neck(self, pose_lm) -> Dict:\n",
        "        \"\"\"Ph√°t hi·ªán head & neck\"\"\"\n",
        "        return {\n",
        "            \"head\": \"head(x=0, y=0, z=0)\",\n",
        "            \"neck\": \"neck(x=0, y=0, z=0)\"\n",
        "        }\n",
        "\n",
        "    def detect_spine(self, pose_lm) -> Dict:\n",
        "        \"\"\"Ph√°t hi·ªán spine\"\"\"\n",
        "        return {\n",
        "            \"spine_01\": \"spine_01(x=0, y=0, z=0)\",\n",
        "            \"spine_02\": \"spine_02(x=0, y=0, z=0)\",\n",
        "            \"spine_03\": \"spine_03(x=0, y=0, z=0)\"\n",
        "        }\n",
        "\n",
        "    def _default_finger(self, finger, suffix):\n",
        "        if finger == 'thumb':\n",
        "            return f\"thumb_02_{suffix}(x=0, y=0, z=0); thumb_03_{suffix}(x=0, y=0, z=0)\"\n",
        "        else:\n",
        "            return f\"{finger}_01_{suffix}(x=0, y=0, z=0); {finger}_02_{suffix}(x=0, y=0, z=0); {finger}_03_{suffix}(x=0, y=0, z=0)\"\n",
        "\n",
        "    def _format_finger(self, finger, suffix, bend_angle):\n",
        "        if finger == 'thumb':\n",
        "            return f\"thumb_02_{suffix}(x=0, y=0, z={bend_angle}); thumb_03_{suffix}(x=0, y=0, z={bend_angle})\"\n",
        "        else:\n",
        "            return f\"{finger}_01_{suffix}(x=0, y=0, z={bend_angle}); {finger}_02_{suffix}(x=0, y=0, z={bend_angle}); {finger}_03_{suffix}(x=0, y=0, z={bend_angle})\"\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN DETECTOR\n",
        "# ============================================================================\n",
        "\n",
        "class SignLanguageDetector:\n",
        "    \"\"\"Main detector v·ªõi Motion Retargeting\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.mp_holistic = mp.solutions.holistic\n",
        "        self.holistic = self.mp_holistic.Holistic(\n",
        "            min_detection_confidence=0.3,\n",
        "            min_tracking_confidence=0.3,\n",
        "            model_complexity=1\n",
        "        )\n",
        "        self.detector = GestureDetector()\n",
        "        print(\"‚úÖ SignLanguageDetector V9 (WITH WRIST ORIENTATION) initialized\")\n",
        "\n",
        "    def process_frame(self, frame) -> Tuple[Optional[Dict], Optional[np.ndarray]]:\n",
        "        \"\"\"Process frame and return gesture data + skeleton image\"\"\"\n",
        "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = self.holistic.process(img_rgb)\n",
        "\n",
        "        if not results.pose_landmarks:\n",
        "            return None, None\n",
        "\n",
        "        # Draw skeleton\n",
        "        skeleton_img = self.draw_skeleton(frame, results)\n",
        "\n",
        "        pose_lm = results.pose_landmarks.landmark\n",
        "\n",
        "        # Detect all body parts\n",
        "        output = {}\n",
        "        output.update(self.detector.detect_spine(pose_lm))\n",
        "        output.update(self.detector.detect_head_neck(pose_lm))\n",
        "\n",
        "        # Facial (default values)\n",
        "        output.update({\n",
        "            \"jaw\": \"jaw(z=0)\",\n",
        "            \"eyelid_l\": \"eyelid_l(z=0)\",\n",
        "            \"eyelid_r\": \"eyelid_r(z=0)\",\n",
        "            \"eyes\": \"eye_l(y=0); eye_r(y=0)\",\n",
        "            \"eyebrows\": \"eyebrow_l(z=0); eyebrow_r(z=0)\",\n",
        "            \"mouth_l\": \"mouth_l(x=0, y=0, z=0)\",\n",
        "            \"mouth_r\": \"mouth_r(x=0, y=0, z=0)\"\n",
        "        })\n",
        "\n",
        "        # Arms (with wrist orientation)\n",
        "        output.update(self.detector.detect_arm(pose_lm, results.left_hand_landmarks, 'left'))\n",
        "        output.update(self.detector.detect_arm(pose_lm, results.right_hand_landmarks, 'right'))\n",
        "\n",
        "        return output, skeleton_img\n",
        "\n",
        "    def draw_skeleton(self, frame, results):\n",
        "        \"\"\"Draw skeleton with wrist orientation indicators\"\"\"\n",
        "        mp_drawing = mp.solutions.drawing_utils\n",
        "        mp_drawing_styles = mp.solutions.drawing_styles\n",
        "        mp_holistic = mp.solutions.holistic\n",
        "\n",
        "        annotated = frame.copy()\n",
        "        h, w, _ = annotated.shape\n",
        "\n",
        "        # Draw pose landmarks\n",
        "        if results.pose_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                annotated, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
        "            )\n",
        "\n",
        "        pose_lm = results.pose_landmarks.landmark if results.pose_landmarks else None\n",
        "\n",
        "        # Draw hand landmarks with wrist orientation\n",
        "        if results.right_hand_landmarks and pose_lm:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                annotated, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                mp_drawing_styles.get_default_hand_connections_style()\n",
        "            )\n",
        "\n",
        "            # ‚úÖ V·∫º WRIST ORIENTATION CHO TAY PH·∫¢I\n",
        "            shoulder_r = pose_lm[12]  # Right shoulder\n",
        "            elbow_r = pose_lm[14]     # Right elbow\n",
        "            wrist_r = pose_lm[16]     # Right wrist\n",
        "\n",
        "            wrist_angles = self.detector.calc.calculate_wrist_orientation(\n",
        "                shoulder_r, elbow_r, wrist_r, results.right_hand_landmarks\n",
        "            )\n",
        "            self._draw_wrist_orientation(annotated, wrist_r, w, h, wrist_angles, \"R\")\n",
        "\n",
        "        if results.left_hand_landmarks and pose_lm:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                annotated, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                mp_drawing_styles.get_default_hand_connections_style()\n",
        "            )\n",
        "\n",
        "            # ‚úÖ V·∫º WRIST ORIENTATION CHO TAY TR√ÅI\n",
        "            shoulder_l = pose_lm[11]  # Left shoulder\n",
        "            elbow_l = pose_lm[13]     # Left elbow\n",
        "            wrist_l = pose_lm[15]     # Left wrist\n",
        "\n",
        "            wrist_angles = self.detector.calc.calculate_wrist_orientation(\n",
        "                shoulder_l, elbow_l, wrist_l, results.left_hand_landmarks\n",
        "            )\n",
        "            self._draw_wrist_orientation(annotated, wrist_l, w, h, wrist_angles, \"L\")\n",
        "\n",
        "        return annotated\n",
        "\n",
        "    def _draw_wrist_orientation(self, img, wrist_pose, img_w, img_h, angles, side):\n",
        "        \"\"\"\n",
        "        ‚úÖ V·∫º CH·ªà B√ÅO WRIST ORIENTATION - FIXED\n",
        "\n",
        "        Args:\n",
        "            img: Image to draw on\n",
        "            wrist_pose: Wrist landmark from pose\n",
        "            img_w: Image width\n",
        "            img_h: Image height\n",
        "            angles: Dict v·ªõi pitch, yaw, roll\n",
        "            side: \"L\" ho·∫∑c \"R\"\n",
        "        \"\"\"\n",
        "        cx = int(wrist_pose.x * img_w)\n",
        "        cy = int(wrist_pose.y * img_h)\n",
        "\n",
        "        if cx < 0 or cx >= img_w or cy < 0 or cy >= img_h:\n",
        "            return\n",
        "\n",
        "        # V·∫Ω box hi·ªÉn th·ªã angles\n",
        "        box_width = 120\n",
        "        box_height = 60\n",
        "        box_x = cx - box_width // 2\n",
        "        box_y = cy - 80\n",
        "\n",
        "        # ƒê·∫£m b·∫£o box kh√¥ng v∆∞·ª£t kh·ªèi frame\n",
        "        box_x = max(0, min(box_x, img_w - box_width))\n",
        "        box_y = max(0, min(box_y, img_h - box_height))\n",
        "\n",
        "        # Background\n",
        "        cv2.rectangle(img,\n",
        "                    (box_x, box_y),\n",
        "                    (box_x + box_width, box_y + box_height),\n",
        "                    (0, 0, 0), -1)\n",
        "        cv2.rectangle(img,\n",
        "                    (box_x, box_y),\n",
        "                    (box_x + box_width, box_y + box_height),\n",
        "                    (0, 255, 255), 2)\n",
        "\n",
        "        # Text\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 0.4\n",
        "        thickness = 1\n",
        "\n",
        "        # Title\n",
        "        cv2.putText(img, f\"{side}_Wrist\",\n",
        "                  (box_x + 5, box_y + 15),\n",
        "                  font, font_scale, (0, 255, 255), thickness)\n",
        "\n",
        "        # Angles\n",
        "        cv2.putText(img, f\"P:{angles['pitch']:6.1f}\",\n",
        "                  (box_x + 5, box_y + 30),\n",
        "                  font, font_scale, (255, 255, 255), thickness)\n",
        "        cv2.putText(img, f\"Y:{angles['yaw']:6.1f}\",\n",
        "                  (box_x + 5, box_y + 45),\n",
        "                  font, font_scale, (255, 255, 255), thickness)\n",
        "        cv2.putText(img, f\"R:{angles['roll']:6.1f}\",\n",
        "                  (box_x + 70, box_y + 30),\n",
        "                  font, font_scale, (255, 255, 255), thickness)\n",
        "\n",
        "    def close(self):\n",
        "        self.holistic.close()\n",
        "\n",
        "# ============================================================================\n",
        "# OPTIMIZED VIDEO PROCESSOR WITH AUTO-TRIM\n",
        "# ============================================================================\n",
        "\n",
        "class OptimizedVideoProcessor:\n",
        "    \"\"\"X·ª≠ l√Ω video t·ªëi ∆∞u v·ªõi auto-trim real-time\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 movement_threshold: float = 0.02,\n",
        "                 arm_down_threshold: float = 0.6,\n",
        "                 min_frames_active: int = 5,\n",
        "                 buffer_frames: int = 3):\n",
        "        self.movement_threshold = movement_threshold\n",
        "        self.arm_down_threshold = arm_down_threshold\n",
        "        self.min_frames_active = min_frames_active\n",
        "        self.buffer_frames = buffer_frames\n",
        "\n",
        "        # MediaPipe\n",
        "        self.mp_holistic = mp.solutions.holistic\n",
        "        self.holistic = self.mp_holistic.Holistic(\n",
        "            min_detection_confidence=0.3,\n",
        "            min_tracking_confidence=0.3,\n",
        "            model_complexity=1\n",
        "        )\n",
        "\n",
        "        # Gesture Detector\n",
        "        self.detector = GestureDetector()\n",
        "\n",
        "        # State tracking\n",
        "        self.prev_landmarks = None\n",
        "        self.consecutive_active_frames = 0\n",
        "        self.started = False\n",
        "        self.start_frame_id = None\n",
        "\n",
        "    def calculate_movement(self, current_landmarks, prev_landmarks) -> float:\n",
        "        \"\"\"T√≠nh to√°n t·ªïng chuy·ªÉn ƒë·ªông c·ªßa c·∫£ 2 tay\"\"\"\n",
        "        if prev_landmarks is None:\n",
        "            return 0.0\n",
        "\n",
        "        indices = [11, 13, 15, 12, 14, 16]\n",
        "        total_movement = 0.0\n",
        "\n",
        "        for idx in indices:\n",
        "            curr = current_landmarks[idx]\n",
        "            prev = prev_landmarks[idx]\n",
        "\n",
        "            dx = curr.x - prev.x\n",
        "            dy = curr.y - prev.y\n",
        "            dz = curr.z - prev.z\n",
        "\n",
        "            distance = np.sqrt(dx*dx + dy*dy + dz*dz)\n",
        "            total_movement += distance\n",
        "\n",
        "        return total_movement / len(indices)\n",
        "\n",
        "    def get_arms_position(self, landmarks) -> float:\n",
        "        \"\"\"L·∫•y v·ªã tr√≠ Y trung b√¨nh c·ªßa 2 c·ªï tay\"\"\"\n",
        "        left_wrist = landmarks[15]\n",
        "        right_wrist = landmarks[16]\n",
        "        return (left_wrist.y + right_wrist.y) / 2\n",
        "\n",
        "    def should_start_processing(self, landmarks) -> bool:\n",
        "        \"\"\"Ki·ªÉm tra xem c√≥ n√™n b·∫Øt ƒë·∫ßu x·ª≠ l√Ω kh√¥ng\"\"\"\n",
        "        if self.started:\n",
        "            return True\n",
        "\n",
        "        movement = self.calculate_movement(landmarks, self.prev_landmarks)\n",
        "\n",
        "        if movement > self.movement_threshold:\n",
        "            self.consecutive_active_frames += 1\n",
        "\n",
        "            if self.consecutive_active_frames >= self.min_frames_active:\n",
        "                self.started = True\n",
        "                print(f\"üé¨ START DETECTED! Beginning analysis...\")\n",
        "                return True\n",
        "        else:\n",
        "            self.consecutive_active_frames = 0\n",
        "\n",
        "        return False\n",
        "\n",
        "    def should_stop_processing(self, landmarks) -> bool:\n",
        "        \"\"\"Ki·ªÉm tra xem c√≥ n√™n d·ª´ng x·ª≠ l√Ω kh√¥ng\"\"\"\n",
        "        if not self.started:\n",
        "            return False\n",
        "\n",
        "        arms_y = self.get_arms_position(landmarks)\n",
        "        movement = self.calculate_movement(landmarks, self.prev_landmarks)\n",
        "\n",
        "        arms_down = arms_y > self.arm_down_threshold\n",
        "        movement_low = movement < self.movement_threshold * 0.5\n",
        "\n",
        "        if arms_down and movement_low:\n",
        "            print(f\"üõë END DETECTED! Stopping analysis...\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def process_video_optimized(self,\n",
        "                                video_source,\n",
        "                                output_json=\"gestures_v6.json\",\n",
        "                                output_dir=\"frames_v6\",\n",
        "                                frames_per_minute=1):\n",
        "        \"\"\"X·ª≠ l√Ω video v·ªõi auto-trim t·ªëi ∆∞u\"\"\"\n",
        "        temp_file = None\n",
        "\n",
        "        try:\n",
        "            # Download n·∫øu l√† URL\n",
        "            if is_url(video_source):\n",
        "                video_path = download_video(video_source)\n",
        "                temp_file = video_path\n",
        "            else:\n",
        "                video_path = video_source\n",
        "                if not os.path.exists(video_path):\n",
        "                    raise ValueError(f\"Video file not found: {video_path}\")\n",
        "\n",
        "            # T·∫°o output folders\n",
        "            Path(output_dir).mkdir(exist_ok=True)\n",
        "            frames_folder = Path(output_dir) / \"original_frames\"\n",
        "            skeleton_folder = Path(output_dir) / \"skeleton_frames\"\n",
        "            frames_folder.mkdir(exist_ok=True)\n",
        "            skeleton_folder.mkdir(exist_ok=True)\n",
        "\n",
        "            # Open video\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "            if not cap.isOpened():\n",
        "                raise ValueError(f\"Cannot open video: {video_path}\")\n",
        "\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            duration_sec = total_frames / fps if fps > 0 else 0\n",
        "            frame_interval = int(fps * 0.1 / frames_per_minute) if fps > 0 else 1\n",
        "\n",
        "            results = []\n",
        "            frame_id = 0\n",
        "            detected_count = 0\n",
        "            skipped_frames = 0\n",
        "\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(f\"üé¨ VIDEO: {video_source}\")\n",
        "            print(f\"üìä FPS: {fps:.2f} | Duration: {duration_sec:.1f}s\")\n",
        "            print(f\"‚è±Ô∏è  Sampling: 1 frame every {frame_interval} frames\")\n",
        "            print(f\"üîç Auto-trim: ENABLED\")\n",
        "            print(f\"{'='*70}\\n\")\n",
        "\n",
        "            print(\"üîé Scanning for start point...\")\n",
        "\n",
        "            # Buffer ƒë·ªÉ l∆∞u frames tr∆∞·ªõc start point\n",
        "            pre_start_buffer = []\n",
        "\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # PHASE 1: T√åM ƒêI·ªÇM B·∫ÆT ƒê·∫¶U\n",
        "                if not self.started:\n",
        "                    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    results_mp = self.holistic.process(img_rgb)\n",
        "\n",
        "                    if results_mp.pose_landmarks:\n",
        "                        landmarks = results_mp.pose_landmarks.landmark\n",
        "\n",
        "                        # L∆∞u v√†o buffer\n",
        "                        if len(pre_start_buffer) < self.buffer_frames:\n",
        "                            pre_start_buffer.append((frame_id, frame, results_mp))\n",
        "                        else:\n",
        "                            pre_start_buffer.pop(0)\n",
        "                            pre_start_buffer.append((frame_id, frame, results_mp))\n",
        "\n",
        "                        # Ki·ªÉm tra xem c√≥ n√™n b·∫Øt ƒë·∫ßu kh√¥ng\n",
        "                        if self.should_start_processing(landmarks):\n",
        "                            self.start_frame_id = frame_id\n",
        "\n",
        "                            # X·ª≠ l√Ω buffer frames\n",
        "                            print(f\"üì¶ Processing {len(pre_start_buffer)} buffer frames...\")\n",
        "                            for buf_frame_id, buf_frame, buf_results in pre_start_buffer:\n",
        "                                gesture_data = self._process_detection(buf_results, buf_frame_id, fps)\n",
        "\n",
        "                                if gesture_data:\n",
        "                                    self._save_frame_data(\n",
        "                                        buf_frame_id, buf_frame,\n",
        "                                        gesture_data, fps,\n",
        "                                        frames_folder, skeleton_folder, results\n",
        "                                    )\n",
        "                                    detected_count += 1\n",
        "\n",
        "                        self.prev_landmarks = landmarks\n",
        "\n",
        "                    skipped_frames += 1\n",
        "\n",
        "                    if frame_id % 300 == 0:\n",
        "                        print(f\"  ‚è≥ Scanning... Frame {frame_id}/{total_frames}\")\n",
        "\n",
        "                    frame_id += 1\n",
        "                    continue\n",
        "\n",
        "                # PHASE 2: X·ª¨ L√ù SAU KHI ƒê√É B·∫ÆT ƒê·∫¶U\n",
        "                if frame_id % frame_interval == 0:\n",
        "                    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    results_mp = self.holistic.process(img_rgb)\n",
        "\n",
        "                    if results_mp.pose_landmarks:\n",
        "                        landmarks = results_mp.pose_landmarks.landmark\n",
        "\n",
        "                        # Ki·ªÉm tra xem c√≥ n√™n d·ª´ng kh√¥ng\n",
        "                        if self.should_stop_processing(landmarks):\n",
        "                            print(f\"‚úÖ Processing complete at frame {frame_id}\")\n",
        "                            break\n",
        "\n",
        "                        # X·ª≠ l√Ω frame\n",
        "                        gesture_data = self._process_detection(results_mp, frame_id, fps)\n",
        "\n",
        "                        if gesture_data:\n",
        "                            self._save_frame_data(\n",
        "                                frame_id, frame,\n",
        "                                gesture_data, fps,\n",
        "                                frames_folder, skeleton_folder, results\n",
        "                            )\n",
        "                            detected_count += 1\n",
        "\n",
        "                            print(f\"  ‚úÖ Frame {frame_id:6d} at {frame_id/fps:7.2f}s - Detected #{detected_count}\")\n",
        "\n",
        "                        self.prev_landmarks = landmarks\n",
        "\n",
        "                frame_id += 1\n",
        "\n",
        "                if frame_id % 300 == 0:\n",
        "                    progress = (frame_id / total_frames * 100) if total_frames > 0 else 0\n",
        "                    print(f\"  ‚è≥ Progress: {frame_id}/{total_frames} ({progress:.1f}%)\")\n",
        "\n",
        "            cap.release()\n",
        "            self.holistic.close()\n",
        "\n",
        "            # Save JSON\n",
        "            with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(f\"‚úÖ COMPLETED!\")\n",
        "            print(f\"üé¨ Start frame: {self.start_frame_id}\")\n",
        "            print(f\"‚è© Skipped frames: {skipped_frames}\")\n",
        "            print(f\"üì¶ Detected: {detected_count} frames\")\n",
        "            print(f\"üíæ JSON: {output_json}\")\n",
        "            print(f\"{'='*70}\\n\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        finally:\n",
        "            if temp_file and os.path.exists(temp_file):\n",
        "                try:\n",
        "                    os.remove(temp_file)\n",
        "                    print(f\"üóëÔ∏è  Cleaned up temporary file: {temp_file}\")\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "    def _process_detection(self, results_mp, frame_id, fps):\n",
        "        \"\"\"X·ª≠ l√Ω detection cho 1 frame\"\"\"\n",
        "        pose_lm = results_mp.pose_landmarks.landmark\n",
        "\n",
        "        output = {}\n",
        "        output.update(self.detector.detect_spine(pose_lm))\n",
        "        output.update(self.detector.detect_head_neck(pose_lm))\n",
        "\n",
        "        # Facial (default values)\n",
        "        output.update({\n",
        "            \"jaw\": \"jaw(z=0)\",\n",
        "            \"eyelid_l\": \"eyelid_l(z=0)\",\n",
        "            \"eyelid_r\": \"eyelid_r(z=0)\",\n",
        "            \"eyes\": \"eye_l(y=0); eye_r(y=0)\",\n",
        "            \"eyebrows\": \"eyebrow_l(z=0); eyebrow_r(z=0)\",\n",
        "            \"mouth_l\": \"mouth_l(x=0, y=0, z=0)\",\n",
        "            \"mouth_r\": \"mouth_r(x=0, y=0, z=0)\"\n",
        "        })\n",
        "\n",
        "        # Arms\n",
        "        output.update(self.detector.detect_arm(pose_lm, results_mp.left_hand_landmarks, 'left'))\n",
        "        output.update(self.detector.detect_arm(pose_lm, results_mp.right_hand_landmarks, 'right'))\n",
        "\n",
        "        return output\n",
        "\n",
        "    def _save_frame_data(self, frame_id, frame, gesture_data, fps,\n",
        "                        frames_folder, skeleton_folder, results):\n",
        "        \"\"\"L∆∞u frame data\"\"\"\n",
        "        timestamp = frame_id / fps if fps > 0 else frame_id\n",
        "        frame_filename = f\"frame_{frame_id:06d}_t{timestamp:.2f}s.jpg\"\n",
        "        skeleton_filename = f\"skeleton_{frame_id:06d}_t{timestamp:.2f}s.jpg\"\n",
        "\n",
        "        cv2.imwrite(str(frames_folder / frame_filename), frame)\n",
        "\n",
        "        results.append({\n",
        "            \"frame\": frame_id,\n",
        "            \"timestamp\": round(timestamp, 3),\n",
        "            \"original_image\": str(frames_folder / frame_filename),\n",
        "            \"skeleton_image\": str(skeleton_folder / skeleton_filename),\n",
        "            \"gestures\": gesture_data\n",
        "        })\n",
        "\n",
        "# ============================================================================\n",
        "# FLASK API\n",
        "# ============================================================================\n",
        "\n",
        "# Setup ngrok\n",
        "conf.get_default().auth_token = \"3721EzVULUpY9QkshdRLFveW6LV_2hLJT8sRukP7E4hw6zz6Y\"\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "RESULTS_DIR = \"api_results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "jobs = {}\n",
        "\n",
        "class DetectionJob:\n",
        "    \"\"\"L·ªõp qu·∫£n l√Ω job x·ª≠ l√Ω video\"\"\"\n",
        "\n",
        "    def __init__(self, job_id, video_url):\n",
        "        self.job_id = job_id\n",
        "        self.video_url = video_url\n",
        "        self.status = \"pending\"\n",
        "        self.progress = 0\n",
        "        self.message = \"\"\n",
        "        self.result_path = None\n",
        "        self.frames_per_minute = 1\n",
        "        self.created_at = datetime.now()\n",
        "        self.started_at = None\n",
        "        self.completed_at = None\n",
        "\n",
        "    def start_processing(self):\n",
        "        \"\"\"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video v·ªõi auto-trim\"\"\"\n",
        "        self.status = \"processing\"\n",
        "        self.started_at = datetime.now()\n",
        "\n",
        "        try:\n",
        "            # T·∫°o th∆∞ m·ª•c k·∫øt qu·∫£\n",
        "            job_dir = os.path.join(RESULTS_DIR, self.job_id)\n",
        "            os.makedirs(job_dir, exist_ok=True)\n",
        "\n",
        "            output_json = os.path.join(job_dir, \"api-gestures.json\")\n",
        "            output_frames = os.path.join(job_dir, \"frames\")\n",
        "\n",
        "            # X·ª≠ l√Ω video\n",
        "            processor = OptimizedVideoProcessor(\n",
        "                movement_threshold=0.02,\n",
        "                arm_down_threshold=0.6,\n",
        "                min_frames_active=5,\n",
        "                buffer_frames=3\n",
        "            )\n",
        "\n",
        "            processor.process_video_optimized(\n",
        "                video_source=self.video_url,\n",
        "                output_json=output_json,\n",
        "                output_dir=output_frames,\n",
        "                frames_per_minute=self.frames_per_minute\n",
        "            )\n",
        "\n",
        "            # C·∫≠p nh·∫≠t tr·∫°ng th√°i\n",
        "            self.status = \"completed\"\n",
        "            self.result_path = output_json\n",
        "            self.completed_at = datetime.now()\n",
        "            self.message = f\"Processing completed\"\n",
        "\n",
        "        except Exception as e:\n",
        "            self.status = \"failed\"\n",
        "            self.completed_at = datetime.now()\n",
        "            self.message = f\"Error: {str(e)}\"\n",
        "            print(f\"Job {self.job_id} failed: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# API ENDPOINTS\n",
        "# ============================================================================\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    \"\"\"Trang ch·ªß API\"\"\"\n",
        "    return jsonify({\n",
        "        \"name\": \"Sign Language Detection API V6\",\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"description\": \"API for sign language gesture detection with auto-trim\",\n",
        "        \"endpoints\": {\n",
        "            \"POST /api/detect\": \"Submit video URL for processing\",\n",
        "            \"GET /api/job/<job_id>\": \"Check job status\",\n",
        "            \"GET /api/job/<job_id>/download\": \"Download results JSON\",\n",
        "            \"GET /api/jobs\": \"List all jobs\",\n",
        "            \"GET /api/health\": \"Health check\"\n",
        "        }\n",
        "    })\n",
        "\n",
        "@app.route('/api/detect', methods=['POST'])\n",
        "def detect_gestures():\n",
        "    \"\"\"\n",
        "    API endpoint ƒë·ªÉ x·ª≠ l√Ω video t·ª´ URL\n",
        "\n",
        "    Request body:\n",
        "    {\n",
        "        \"video_url\": \"https://example.com/video.mp4\",\n",
        "        \"frames_per_minute\": 1 (optional, default: 1)\n",
        "    }\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "\n",
        "        if not data or 'video_url' not in data:\n",
        "            return jsonify({\"error\": \"Missing video_url in request body\"}), 400\n",
        "\n",
        "        video_url = data['video_url'].strip()\n",
        "\n",
        "        if not (video_url.startswith('http://') or video_url.startswith('https://')):\n",
        "            return jsonify({\"error\": \"Invalid URL. Must start with http:// or https://\"}), 400\n",
        "\n",
        "        # T·∫°o job ID\n",
        "        job_id = str(uuid.uuid4())\n",
        "\n",
        "        # T·∫°o job m·ªõi\n",
        "        job = DetectionJob(job_id, video_url)\n",
        "\n",
        "        # C·∫≠p nh·∫≠t frames_per_minute n·∫øu c√≥\n",
        "        if 'frames_per_minute' in data:\n",
        "            try:\n",
        "                fpm = float(data['frames_per_minute'])\n",
        "                if 0.1 <= fpm <= 60:\n",
        "                    job.frames_per_minute = fpm\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # L∆∞u job\n",
        "        jobs[job_id] = job\n",
        "\n",
        "        # Ch·∫°y x·ª≠ l√Ω trong thread ri√™ng\n",
        "        thread = threading.Thread(target=job.start_processing)\n",
        "        thread.daemon = True\n",
        "        thread.start()\n",
        "\n",
        "        # Tr·∫£ v·ªÅ th√¥ng tin job\n",
        "        return jsonify({\n",
        "            \"job_id\": job_id,\n",
        "            \"status\": job.status,\n",
        "            \"message\": \"Job created and processing started\",\n",
        "            \"video_url\": video_url,\n",
        "            \"created_at\": job.created_at.isoformat(),\n",
        "            \"check_status_url\": f\"/api/job/{job_id}\",\n",
        "            \"download_url\": f\"/api/job/{job_id}/download\"\n",
        "        }), 202\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"Server error: {str(e)}\"}), 500\n",
        "\n",
        "@app.route('/api/job/<job_id>', methods=['GET'])\n",
        "def get_job_status(job_id):\n",
        "    \"\"\"\n",
        "    Ki·ªÉm tra tr·∫°ng th√°i c·ªßa job\n",
        "\n",
        "    Response:\n",
        "    {\n",
        "        \"job_id\": \"uuid\",\n",
        "        \"status\": \"pending|processing|completed|failed\",\n",
        "        \"progress\": 0-100,\n",
        "        \"message\": \"Status message\",\n",
        "        \"video_url\": \"original_url\",\n",
        "        \"created_at\": \"timestamp\",\n",
        "        \"started_at\": \"timestamp\",\n",
        "        \"completed_at\": \"timestamp\",\n",
        "        \"result_available\": true/false\n",
        "    }\n",
        "    \"\"\"\n",
        "    if job_id not in jobs:\n",
        "        return jsonify({\"error\": f\"Job {job_id} not found\"}), 404\n",
        "\n",
        "    job = jobs[job_id]\n",
        "\n",
        "    # T√≠nh progress\n",
        "    if job.status == \"processing\":\n",
        "        job.progress = 50  # C√≥ th·ªÉ c·∫£i ti·∫øn th√™m\n",
        "    elif job.status == \"completed\":\n",
        "        job.progress = 100\n",
        "\n",
        "    return jsonify({\n",
        "        \"job_id\": job.job_id,\n",
        "        \"status\": job.status,\n",
        "        \"progress\": job.progress,\n",
        "        \"message\": job.message,\n",
        "        \"video_url\": job.video_url,\n",
        "        \"frames_per_minute\": job.frames_per_minute,\n",
        "        \"created_at\": job.created_at.isoformat() if job.created_at else None,\n",
        "        \"started_at\": job.started_at.isoformat() if job.started_at else None,\n",
        "        \"completed_at\": job.completed_at.isoformat() if job.completed_at else None,\n",
        "        \"result_available\": job.status == \"completed\" and job.result_path is not None\n",
        "    })\n",
        "\n",
        "@app.route('/api/job/<job_id>/download', methods=['GET'])\n",
        "def download_results(job_id):\n",
        "    \"\"\"T·∫£i v·ªÅ file JSON k·∫øt qu·∫£\"\"\"\n",
        "    if job_id not in jobs:\n",
        "        return jsonify({\"error\": f\"Job {job_id} not found\"}), 404\n",
        "\n",
        "    job = jobs[job_id]\n",
        "\n",
        "    if job.status != \"completed\":\n",
        "        return jsonify({\"error\": f\"Job is not completed yet. Current status: {job.status}\"}), 400\n",
        "\n",
        "    if not job.result_path or not os.path.exists(job.result_path):\n",
        "        return jsonify({\"error\": \"Result file not found\"}), 404\n",
        "\n",
        "    return send_file(\n",
        "        job.result_path,\n",
        "        as_attachment=True,\n",
        "        download_name=f\"gestures_{job_id}.json\",\n",
        "        mimetype='application/json'\n",
        "    )\n",
        "\n",
        "@app.route('/api/job/<job_id>/preview', methods=['GET'])\n",
        "def preview_results(job_id):\n",
        "    \"\"\"\n",
        "    Xem tr∆∞·ªõc k·∫øt qu·∫£ (l·∫•y m·ªôt v√†i frame ƒë·∫ßu ti√™n)\n",
        "\n",
        "    Query parameters:\n",
        "    - limit: s·ªë l∆∞·ª£ng frame mu·ªën xem (default: 5)\n",
        "    \"\"\"\n",
        "    if job_id not in jobs:\n",
        "        return jsonify({\"error\": f\"Job {job_id} not found\"}), 404\n",
        "\n",
        "    job = jobs[job_id]\n",
        "\n",
        "    if job.status != \"completed\":\n",
        "        return jsonify({\"error\": f\"Job is not completed yet. Current status: {job.status}\"}), 400\n",
        "\n",
        "    if not job.result_path or not os.path.exists(job.result_path):\n",
        "        return jsonify({\"error\": \"Result file not found\"}), 404\n",
        "\n",
        "    try:\n",
        "        with open(job.result_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        limit = request.args.get('limit', default=5, type=int)\n",
        "        preview_data = data[:limit] if isinstance(data, list) else data\n",
        "\n",
        "        return jsonify({\n",
        "            \"job_id\": job_id,\n",
        "            \"total_frames\": len(data) if isinstance(data, list) else 1,\n",
        "            \"preview_limit\": limit,\n",
        "            \"preview_data\": preview_data\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"Error reading result file: {str(e)}\"}), 500\n",
        "\n",
        "@app.route('/api/jobs', methods=['GET'])\n",
        "def list_jobs():\n",
        "    \"\"\"\n",
        "    Li·ªát k√™ t·∫•t c·∫£ jobs\n",
        "\n",
        "    Query parameters:\n",
        "    - status: l·ªçc theo status (pending, processing, completed, failed)\n",
        "    - limit: s·ªë l∆∞·ª£ng job t·ªëi ƒëa (default: 50)\n",
        "    \"\"\"\n",
        "    status_filter = request.args.get('status')\n",
        "    limit = request.args.get('limit', default=50, type=int)\n",
        "\n",
        "    filtered_jobs = []\n",
        "    for job_id, job in jobs.items():\n",
        "        if status_filter and job.status != status_filter:\n",
        "            continue\n",
        "\n",
        "        filtered_jobs.append({\n",
        "            \"job_id\": job_id,\n",
        "            \"status\": job.status,\n",
        "            \"video_url\": job.video_url,\n",
        "            \"created_at\": job.created_at.isoformat() if job.created_at else None,\n",
        "            \"completed_at\": job.completed_at.isoformat() if job.completed_at else None,\n",
        "            \"result_available\": job.status == \"completed\" and job.result_path is not None\n",
        "        })\n",
        "\n",
        "    # S·∫Øp x·∫øp theo th·ªùi gian t·∫°o (m·ªõi nh·∫•t tr∆∞·ªõc)\n",
        "    filtered_jobs.sort(key=lambda x: x['created_at'] if x['created_at'] else '', reverse=True)\n",
        "    filtered_jobs = filtered_jobs[:limit]\n",
        "\n",
        "    return jsonify({\n",
        "        \"total_jobs\": len(jobs),\n",
        "        \"filtered_count\": len(filtered_jobs),\n",
        "        \"jobs\": filtered_jobs\n",
        "    })\n",
        "\n",
        "@app.route('/api/job/<job_id>', methods=['DELETE'])\n",
        "def delete_job(job_id):\n",
        "    \"\"\"X√≥a job v√† c√°c file li√™n quan\"\"\"\n",
        "    if job_id not in jobs:\n",
        "        return jsonify({\"error\": f\"Job {job_id} not found\"}), 404\n",
        "\n",
        "    job = jobs[job_id]\n",
        "\n",
        "    try:\n",
        "        # X√≥a th∆∞ m·ª•c k·∫øt qu·∫£ n·∫øu c√≥\n",
        "        job_dir = os.path.join(RESULTS_DIR, job_id)\n",
        "        if os.path.exists(job_dir):\n",
        "            import shutil\n",
        "            shutil.rmtree(job_dir)\n",
        "\n",
        "        # X√≥a job kh·ªèi dictionary\n",
        "        del jobs[job_id]\n",
        "\n",
        "        return jsonify({\"message\": f\"Job {job_id} deleted successfully\"})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"Error deleting job: {str(e)}\"}), 500\n",
        "\n",
        "@app.route('/api/health', methods=['GET'])\n",
        "def health_check():\n",
        "    \"\"\"Endpoint ki·ªÉm tra t√¨nh tr·∫°ng API\"\"\"\n",
        "    return jsonify({\n",
        "        \"status\": \"healthy\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"active_jobs\": len([j for j in jobs.values() if j.status == \"processing\"]),\n",
        "        \"total_jobs\": len(jobs)\n",
        "    })\n",
        "\n",
        "# ============================================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def cleanup_old_jobs():\n",
        "    \"\"\"X√≥a c√°c jobs c≈© h∆°n 24 gi·ªù\"\"\"\n",
        "    try:\n",
        "        cutoff_time = datetime.now().timestamp() - (24 * 3600)\n",
        "        jobs_to_delete = []\n",
        "\n",
        "        for job_id, job in jobs.items():\n",
        "            if job.completed_at and job.completed_at.timestamp() < cutoff_time:\n",
        "                jobs_to_delete.append(job_id)\n",
        "\n",
        "        for job_id in jobs_to_delete:\n",
        "            try:\n",
        "                job_dir = os.path.join(RESULTS_DIR, job_id)\n",
        "                if os.path.exists(job_dir):\n",
        "                    import shutil\n",
        "                    shutil.rmtree(job_dir)\n",
        "                del jobs[job_id]\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(f\"Cleaned up {len(jobs_to_delete)} old jobs\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in cleanup: {e}\")\n",
        "\n",
        "@app.before_request\n",
        "def log_request():\n",
        "    \"\"\"Middleware ƒë·ªÉ log request\"\"\"\n",
        "    if request.path not in ['/health', '/']:\n",
        "        print(f\"[{datetime.now().isoformat()}] {request.method} {request.path}\")\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SIGN LANGUAGE DETECTION API V6\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Cleanup jobs c≈©\n",
        "    cleanup_old_jobs()\n",
        "\n",
        "    # T·∫Øt c√°c tunnel ngrok c≈©\n",
        "    try:\n",
        "        ngrok.kill()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # T·∫°o tunnel ngrok\n",
        "    try:\n",
        "        public_url = ngrok.connect(5000)\n",
        "        print(f\"üåç PUBLIC URL: {public_url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Ngrok error: {e}\")\n",
        "        print(\"Running in local mode only\")\n",
        "\n",
        "    print(f\"üè† Local URL: http://localhost:5000\")\n",
        "    print(f\"üìÅ Results directory: {RESULTS_DIR}\")\n",
        "    print(\"\\nüìå Endpoints:\")\n",
        "    print(\"  POST /api/detect              - Submit video URL\")\n",
        "    print(\"  GET  /api/job/<id>            - Check job status\")\n",
        "    print(\"  GET  /api/job/<id>/download   - Download results\")\n",
        "    print(\"  GET  /api/job/<id>/preview    - Preview results\")\n",
        "    print(\"  GET  /api/jobs                - List all jobs\")\n",
        "    print(\"  DELETE /api/job/<id>          - Delete job\")\n",
        "    print(\"  GET  /api/health              - Health check\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Ch·∫°y server\n",
        "    app.run(host='0.0.0.0', port=5000, debug=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}