{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaiKhoa0101/MachineLearning/blob/main/CODE_Detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "37No4x_fsDeR",
        "outputId": "90bb5f15-3256-4b15-8c2c-4ae7d194500d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: mediapipe 0.10.32\n",
            "Uninstalling mediapipe-0.10.32:\n",
            "  Successfully uninstalled mediapipe-0.10.32\n",
            "Files removed: 24\n",
            "Collecting mediapipe==0.10.18\n",
            "  Downloading mediapipe-0.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (25.12.19)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (0.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe==0.10.18)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (4.13.0.92)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe==0.10.18)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (0.5.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe==0.10.18) (0.2.1)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.18) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.18) (0.5.4)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe==0.10.18)\n",
            "  Downloading jax-0.9.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.18)\n",
            "  Downloading jaxlib-0.9.0.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe==0.10.18)\n",
            "  Downloading jax-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.18)\n",
            "  Downloading jaxlib-0.9.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe==0.10.18)\n",
            "  Downloading jax-0.8.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.18)\n",
            "  Downloading jaxlib-0.8.3-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe==0.10.18)\n",
            "  Downloading jax-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.18)\n",
            "  Downloading jaxlib-0.8.2-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe==0.10.18)\n",
            "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.18)\n",
            "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe==0.10.18)\n",
            "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.18)\n",
            "  Downloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe==0.10.18)\n",
            "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.18)\n",
            "  Downloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.18) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe==0.10.18) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe==0.10.18) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe==0.10.18)\n",
            "  Downloading opencv_contrib_python-4.13.0.90-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "  Downloading opencv_contrib_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.18) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->sounddevice>=0.4.4->mediapipe==0.10.18) (3.0)\n",
            "Downloading mediapipe-0.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl (81.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, opencv-contrib-python, jaxlib, jax, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.6\n",
            "    Uninstalling protobuf-5.29.6:\n",
            "      Successfully uninstalled protobuf-5.29.6\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.13.0.92\n",
            "    Uninstalling opencv-contrib-python-4.13.0.92:\n",
            "      Successfully uninstalled opencv-contrib-python-4.13.0.92\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 4.25.8 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opentelemetry-proto 1.38.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.15.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.7.1 jaxlib-0.7.1 mediapipe-0.10.18 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2",
                  "google",
                  "jax",
                  "jaxlib",
                  "mediapipe",
                  "numpy"
                ]
              },
              "id": "9bf32b80320e41d196460a1e23990a31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall mediapipe -y\n",
        "!pip cache purge\n",
        "!pip install mediapipe==0.10.18\n",
        "!python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X5sxNk8vHm1k",
        "outputId": "c57967f6-bf1e-49d3-c655-975d570a17ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.18)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.12.19)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->sounddevice>=0.4.4->mediapipe) (3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jUn-fcbq-RP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "276b0bf7-4b88-4334-84ad-0d864e4d2e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'mediapipe' has no attribute 'solutions'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3880367055.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# N·∫øu True, test ti·∫øp:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'mediapipe' has no attribute 'solutions'"
          ]
        }
      ],
      "source": [
        "import mediapipe as mp\n",
        "\n",
        "# Ki·ªÉm tra xem c√≥ module solutions kh√¥ng\n",
        "print(hasattr(mp, 'solutions'))  # Ph·∫£i tr·∫£ v·ªÅ True\n",
        "\n",
        "# N·∫øu True, test ti·∫øp:\n",
        "print(mp.solutions.hands)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import json\n",
        "from math import sqrt, atan2, degrees, acos, asin, atan\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "\"\"\"\n",
        "SIGN LANGUAGE DETECTOR V9 - COMPLETE WITH WRIST ORIENTATION\n",
        "============================================================\n",
        "‚úÖ Th√™m: Wrist orientation detection (pitch, yaw, roll)\n",
        "‚úÖ Full body tracking ho√†n ch·ªânh\n",
        "\n",
        "Author: Claude\n",
        "Date: 2026-01-09\n",
        "\"\"\"\n",
        "\n",
        "class RigConfiguration:\n",
        "    \"\"\"C·∫•u h√¨nh √°nh x·∫° gi·ªØa g√≥c v·∫≠t l√Ω v√† tr·ª•c x∆∞∆°ng c·ªßa Model 3D\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # UPPER ARM\n",
        "        self.UPPERARM_L = {\n",
        "            \"y\": {\"axis\": \"y\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"z\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"x\": {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.UPPERARM_R = {\n",
        "            \"y\": {\"axis\": \"y\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"z\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"x\": {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "        # LOWER ARM\n",
        "        self.LOWERARM_L = {\n",
        "            \"bend\": {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "            \"rotation\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.LOWERARM_R = {\n",
        "            \"bend\": {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "            \"rotation\": {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "        # WRIST/HAND - ‚úÖ C·∫¨P NH·∫¨T ƒê·∫¶Y ƒê·ª¶ 3-DOF\n",
        "        self.HAND_L = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},   # C√∫i/ng·ª≠a c·ªï tay\n",
        "            \"yaw\": {\"axis\": \"y\", \"scale\": 0.5, \"offset\": 0},     # Quay tr√°i/ph·∫£i\n",
        "            \"roll\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}     # Xoay (pronation/supination)\n",
        "        }\n",
        "        self.HAND_R = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\": {\"axis\": \"y\", \"scale\": 0.5, \"offset\": 0},\n",
        "            \"roll\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "        # FINGERS\n",
        "        self.FINGER_CONFIG = {\"bend\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0}}\n",
        "\n",
        "        # HEAD & NECK\n",
        "        self.HEAD = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"roll\": {\"axis\": \"y\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.NECK = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 0.5, \"offset\": 0},\n",
        "            \"yaw\": {\"axis\": \"x\", \"scale\": 0.5, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "        # SPINE\n",
        "        self.SPINE = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\": {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "    def apply_mapping(self, physical_angles: Dict, config: Dict) -> Dict:\n",
        "        \"\"\"√Åp d·ª•ng configuration ƒë·ªÉ chuy·ªÉn g√≥c v·∫≠t l√Ω th√†nh output Model\"\"\"\n",
        "        result = {\"x\": 0, \"y\": 0, \"z\": 0}\n",
        "        for angle_type, angle_value in physical_angles.items():\n",
        "            if angle_type in config:\n",
        "                mapping = config[angle_type]\n",
        "                axis = mapping[\"axis\"]\n",
        "                scale = mapping[\"scale\"]\n",
        "                offset = mapping[\"offset\"]\n",
        "                result[axis] = round(angle_value * scale + offset, 2)\n",
        "        return result\n",
        "\n",
        "# ============================================================================\n",
        "# PHYSICAL ANGLE CALCULATOR\n",
        "# ============================================================================\n",
        "\n",
        "class PhysicalAngleCalculator:\n",
        "    \"\"\"T√≠nh g√≥c v·∫≠t l√Ω th·ª±c t·∫ø t·ª´ MediaPipe landmarks\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_elbow_bend(shoulder, elbow, wrist) -> float:\n",
        "        \"\"\"T√≠nh g√≥c g·∫≠p khu·ª∑u tay (Law of Cosines)\"\"\"\n",
        "        a = np.linalg.norm([elbow.x - shoulder.x, elbow.y - shoulder.y, elbow.z - shoulder.z])\n",
        "        b = np.linalg.norm([wrist.x - elbow.x, wrist.y - elbow.y, wrist.z - elbow.z])\n",
        "        c = np.linalg.norm([wrist.x - shoulder.x, wrist.y - shoulder.y, wrist.z - shoulder.z])\n",
        "\n",
        "        cos_angle = (a*a + b*b - c*c) / (2 * a * b + 1e-6)\n",
        "        cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
        "        angle = degrees(acos(cos_angle))\n",
        "        return angle\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_forearm_rotation(shoulder, elbow, wrist) -> float:\n",
        "        \"\"\"T√≠nh g√≥c xoay c·∫≥ng tay\"\"\"\n",
        "        upper_arm = np.array([\n",
        "            elbow.x - shoulder.x,\n",
        "            elbow.y - shoulder.y,\n",
        "            elbow.z - shoulder.z\n",
        "        ])\n",
        "        upper_arm = upper_arm / (np.linalg.norm(upper_arm) + 1e-6)\n",
        "\n",
        "        forearm = np.array([\n",
        "            wrist.x - elbow.x,\n",
        "            wrist.y - elbow.y,\n",
        "            wrist.z - elbow.z\n",
        "        ])\n",
        "        forearm = forearm / (np.linalg.norm(forearm) + 1e-6)\n",
        "\n",
        "        projection = np.dot(forearm, upper_arm) * upper_arm\n",
        "        perpendicular = forearm - projection\n",
        "        perp_length = np.linalg.norm(perpendicular) + 1e-6\n",
        "        perpendicular = perpendicular / perp_length\n",
        "\n",
        "        reference = np.array([0, 1, 0])\n",
        "        ref_proj = reference - np.dot(reference, upper_arm) * upper_arm\n",
        "        ref_length = np.linalg.norm(ref_proj) + 1e-6\n",
        "        ref_proj = ref_proj / ref_length\n",
        "\n",
        "        cos_angle = np.clip(np.dot(perpendicular, ref_proj), -1.0, 1.0)\n",
        "        rotation_angle = degrees(acos(cos_angle))\n",
        "\n",
        "        cross = np.cross(ref_proj, perpendicular)\n",
        "        if np.dot(cross, upper_arm) < 0:\n",
        "            rotation_angle = -rotation_angle\n",
        "\n",
        "        return round(rotation_angle, 2)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_wrist_orientation(shoulder, elbow, wrist, hand_landmarks) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        ‚úÖ T√çNH G√ìC C·ªî TAY - SIMPLE Y-AXIS ANGLE\n",
        "\n",
        "        Ch·ªâ d√πng Y component ƒë·ªÉ t√≠nh flexion/extension\n",
        "        \"\"\"\n",
        "        if hand_landmarks is None:\n",
        "            return {\"pitch\": 0.0, \"yaw\": 0.0, \"roll\": 0.0}\n",
        "\n",
        "        wrist_lm = hand_landmarks.landmark[0]     # Wrist\n",
        "        middle_mcp = hand_landmarks.landmark[9]   # Middle base\n",
        "\n",
        "        # Ch·ªâ quan t√¢m ƒë·∫øn Y difference (vertical)\n",
        "        dy = middle_mcp.y - wrist_lm.y\n",
        "\n",
        "        # T√≠nh g√≥c t·ª´ Y component\n",
        "        # Trong MediaPipe hand: Y tƒÉng = xu·ªëng d∆∞·ªõi\n",
        "        # dy > 0 = hand pointing down (flexion)\n",
        "        # dy < 0 = hand pointing up (extension)\n",
        "\n",
        "        # Scale xu·ªëng ƒë·ªÉ c√≥ g√≥c h·ª£p l√Ω (d·ª±a v√†o th·ª±c nghi·ªám)\n",
        "        pitch = np.clip(dy * 60, -40, 40)\n",
        "\n",
        "        # Clamp\n",
        "        pitch = np.clip(pitch, -45, 90)\n",
        "\n",
        "        return {\n",
        "            \"pitch\": round(pitch, 2),\n",
        "            \"yaw\": 0.0,\n",
        "            \"roll\": 0.0\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_arm_orientation(shoulder, elbow, wrist=None):\n",
        "        \"\"\"T√≠nh orientation c√°nh tay b·∫±ng spherical coordinates\"\"\"\n",
        "\n",
        "        dx = elbow.x - shoulder.x\n",
        "        dy = elbow.y - shoulder.y\n",
        "        dz = elbow.z - shoulder.z\n",
        "\n",
        "        length = sqrt(dx*dx + dy*dy + dz*dz) + 1e-6\n",
        "        dx /= length\n",
        "        dy /= length\n",
        "        dz /= length\n",
        "\n",
        "        # Yaw: xoay ngang (tr√°i/ph·∫£i)\n",
        "        yaw = degrees(atan2(dx, dz))\n",
        "\n",
        "        # Pitch: n√¢ng/h·∫° tay\n",
        "        pitch = degrees(atan2(-dy, sqrt(dx*dx + dz*dz)))\n",
        "\n",
        "        # Roll: xoay quanh tr·ª•c arm\n",
        "        roll = 0.0\n",
        "\n",
        "        if wrist is not None:\n",
        "            wx = wrist.x - elbow.x\n",
        "            wy = wrist.y - elbow.y\n",
        "            wz = wrist.z - elbow.z\n",
        "\n",
        "            arm_axis = np.array([dx, dy, dz])\n",
        "            wrist_vec = np.array([wx, wy, wz])\n",
        "\n",
        "            projection = np.dot(wrist_vec, arm_axis) * arm_axis\n",
        "            perpendicular = wrist_vec - projection\n",
        "\n",
        "            perp_length = np.linalg.norm(perpendicular) + 1e-6\n",
        "            perpendicular /= perp_length\n",
        "\n",
        "            ref = np.array([0, -1, 0])\n",
        "            ref_proj = ref - np.dot(ref, arm_axis) * arm_axis\n",
        "            ref_proj /= np.linalg.norm(ref_proj) + 1e-6\n",
        "\n",
        "            cos_angle = np.clip(np.dot(perpendicular, ref_proj), -1.0, 1.0)\n",
        "            roll = degrees(acos(cos_angle))\n",
        "\n",
        "            if np.dot(np.cross(ref_proj, perpendicular), arm_axis) < 0:\n",
        "                roll = -roll\n",
        "\n",
        "        return {\n",
        "            \"x\": round(roll, 2),\n",
        "            \"y\": round(yaw, 2),\n",
        "            \"z\": round(pitch, 2)\n",
        "        }\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_finger_bend(landmarks, finger_ids) -> float:\n",
        "        \"\"\"\n",
        "        T√≠nh g√≥c g·∫≠p t·∫°i kh·ªõp PIP (·ªïn ƒë·ªãnh h∆°n)\n",
        "        D√πng vector dot product thay v√¨ Law of Cosines\n",
        "        \"\"\"\n",
        "\n",
        "        # L·∫•y 3 ƒëi·ªÉm ch√≠nh: MCP - PIP - DIP\n",
        "        p1 = landmarks[finger_ids[0]]  # MCP\n",
        "        p2 = landmarks[finger_ids[1]]  # PIP (kh·ªõp ch√≠nh)\n",
        "        p3 = landmarks[finger_ids[2]]  # DIP\n",
        "\n",
        "        v1 = np.array([p1.x - p2.x, p1.y - p2.y, p1.z - p2.z])\n",
        "        v2 = np.array([p3.x - p2.x, p3.y - p2.y, p3.z - p2.z])\n",
        "\n",
        "        v1 = v1 / (np.linalg.norm(v1) + 1e-6)\n",
        "        v2 = v2 / (np.linalg.norm(v2) + 1e-6)\n",
        "\n",
        "        cos_angle = np.clip(np.dot(v1, v2), -1.0, 1.0)\n",
        "        angle = degrees(acos(cos_angle))\n",
        "\n",
        "        # Chuy·ªÉn v·ªÅ bend (0 = th·∫≥ng, tƒÉng d·∫ßn khi g·∫≠p)\n",
        "        bend = 180 - angle\n",
        "\n",
        "        return round(bend, 2)\n",
        "\n",
        "\n",
        "    # fix\n",
        "    # def calculate_finger_bend(landmarks, finger_ids) -> float:\n",
        "    #     \"\"\"T√≠nh g√≥c g·∫≠p trung b√¨nh c·ªßa ng√≥n tay\"\"\"\n",
        "    #     total_angle = 0\n",
        "    #     count = 0\n",
        "\n",
        "    #     for i in range(1, len(finger_ids)-1):\n",
        "    #         p1 = landmarks[finger_ids[i-1]]\n",
        "    #         p2 = landmarks[finger_ids[i]]\n",
        "    #         p3 = landmarks[finger_ids[i+1]]\n",
        "\n",
        "    #         a = np.linalg.norm([p2.x - p1.x, p2.y - p1.y, p2.z - p1.z])\n",
        "    #         b = np.linalg.norm([p3.x - p2.x, p3.y - p2.y, p3.z - p2.z])\n",
        "    #         c = np.linalg.norm([p3.x - p1.x, p3.y - p1.y, p3.z - p1.z])\n",
        "\n",
        "    #         cos_angle = (a*a + b*b - c*c) / (2 * a * b + 1e-6)\n",
        "    #         cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
        "\n",
        "    #         angle = degrees(acos(cos_angle))\n",
        "    #         total_angle += (180 - angle)\n",
        "    #         count += 1\n",
        "\n",
        "    #     avg_angle = total_angle / count if count > 0 else 0\n",
        "    #     return round(avg_angle, 2)\n",
        "\n",
        "# ============================================================================\n",
        "# GESTURE DETECTOR\n",
        "# ============================================================================\n",
        "\n",
        "class GestureDetector:\n",
        "    \"\"\"Detector s·ª≠ d·ª•ng Physical Calculation + Rig Configuration\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.calc = PhysicalAngleCalculator()\n",
        "        self.rig = RigConfiguration()\n",
        "\n",
        "    def detect_arm(self, pose_lm, hand_landmarks, side='left') -> Dict:\n",
        "        \"\"\"Ph√°t hi·ªán v√† chuy·ªÉn ƒë·ªïi g√≥c c√°nh tay - ‚úÖ ƒê√É C√ì WRIST ORIENTATION\"\"\"\n",
        "        if side == 'left':\n",
        "            shoulder, elbow, wrist = pose_lm[11], pose_lm[13], pose_lm[15]\n",
        "            suffix = 'l'\n",
        "            upperarm_config = self.rig.UPPERARM_L\n",
        "            lowerarm_config = self.rig.LOWERARM_L\n",
        "            hand_config = self.rig.HAND_L\n",
        "        else:\n",
        "            shoulder, elbow, wrist = pose_lm[12], pose_lm[14], pose_lm[16]\n",
        "            suffix = 'r'\n",
        "            upperarm_config = self.rig.UPPERARM_R\n",
        "            lowerarm_config = self.rig.LOWERARM_R\n",
        "            hand_config = self.rig.HAND_R\n",
        "\n",
        "        # Calculate angles\n",
        "        upperarm_angles = self.calc.calculate_arm_orientation(shoulder, elbow)\n",
        "\n",
        "        if hand_landmarks is None:\n",
        "            elbow_bend = 0\n",
        "            forearm_rotation = 0\n",
        "            wrist_angles = {\"pitch\": 0, \"yaw\": 0, \"roll\": 0}\n",
        "        else:\n",
        "            elbow_bend = self.calc.calculate_elbow_bend(shoulder, elbow, wrist)\n",
        "            forearm_rotation = self.calc.calculate_forearm_rotation(shoulder, elbow, wrist)\n",
        "            # ‚úÖ FIXED: Truy·ªÅn ƒë·∫ßy ƒë·ªß shoulder, elbow, wrist\n",
        "            wrist_angles = self.calc.calculate_wrist_orientation(\n",
        "                shoulder, elbow, wrist, hand_landmarks\n",
        "            )\n",
        "        # Apply rig configuration\n",
        "        upperarm_result = self.rig.apply_mapping(upperarm_angles, upperarm_config)\n",
        "\n",
        "        lowerarm_result = self.rig.apply_mapping({\n",
        "            \"bend\": elbow_bend,\n",
        "            \"rotation\": forearm_rotation\n",
        "        }, lowerarm_config)\n",
        "\n",
        "        # ‚úÖ MAP WRIST ORIENTATION\n",
        "        hand_result = self.rig.apply_mapping(wrist_angles, hand_config)\n",
        "\n",
        "        output = {\n",
        "            f\"shoulder_{suffix}\": f\"shoulder_{suffix}(x=0, y=0, z=0)\",\n",
        "            f\"upperarm_{suffix}\": f\"upperarm_{suffix}(x={upperarm_result['x']}, y={upperarm_result['y']}, z={upperarm_result['z']})\",\n",
        "            f\"lowerarm_{suffix}\": f\"lowerarm_{suffix}(x={lowerarm_result['x']}, y={lowerarm_result['y']}, z={lowerarm_result['z']})\",\n",
        "            # ‚úÖ WRIST ORIENTATION ƒê·∫¶Y ƒê·ª¶\n",
        "            f\"hand_{suffix}\": f\"hand_{suffix}(x={hand_result['x']}, y={hand_result['y']}, z={hand_result['z']})\"\n",
        "        }\n",
        "\n",
        "        # Fingers\n",
        "        if hand_landmarks is None:\n",
        "            for finger in ['thumb', 'index', 'middle', 'ring', 'pinky']:\n",
        "                output[f\"{finger}_{suffix}\"] = self._default_finger(finger, suffix)\n",
        "        else:\n",
        "            hand_lm = hand_landmarks.landmark\n",
        "\n",
        "            finger_ids = {\n",
        "                \"thumb\": [1, 2, 3, 4],\n",
        "                \"index\": [5, 6, 7, 8],\n",
        "                \"middle\": [9, 10, 11, 12],\n",
        "                \"ring\": [13, 14, 15, 16],\n",
        "                \"pinky\": [17, 18, 19, 20]\n",
        "            }\n",
        "\n",
        "            for fname, ids in finger_ids.items():\n",
        "                bend = self.calc.calculate_finger_bend(hand_lm, ids)\n",
        "                finger_result = self.rig.apply_mapping({\"bend\": bend}, self.rig.FINGER_CONFIG)\n",
        "                output[f\"{fname}_{suffix}\"] = self._format_finger(fname, suffix, finger_result['z'])\n",
        "\n",
        "        return output\n",
        "\n",
        "    def detect_head_neck(self, pose_lm) -> Dict:\n",
        "        \"\"\"Ph√°t hi·ªán head & neck\"\"\"\n",
        "        return {\n",
        "            \"head\": \"head(x=0, y=0, z=0)\",\n",
        "            \"neck\": \"neck(x=0, y=0, z=0)\"\n",
        "        }\n",
        "\n",
        "    def detect_spine(self, pose_lm) -> Dict:\n",
        "        \"\"\"Ph√°t hi·ªán spine\"\"\"\n",
        "        return {\n",
        "            \"spine_01\": \"spine_01(x=0, y=0, z=0)\",\n",
        "            \"spine_02\": \"spine_02(x=0, y=0, z=0)\",\n",
        "            \"spine_03\": \"spine_03(x=0, y=0, z=0)\"\n",
        "        }\n",
        "\n",
        "    def _default_finger(self, finger, suffix):\n",
        "        if finger == 'thumb':\n",
        "            return f\"thumb_02_{suffix}(x=0, y=0, z=0); thumb_03_{suffix}(x=0, y=0, z=0)\"\n",
        "        else:\n",
        "            return f\"{finger}_01_{suffix}(x=0, y=0, z=0); {finger}_02_{suffix}(x=0, y=0, z=0); {finger}_03_{suffix}(x=0, y=0, z=0)\"\n",
        "\n",
        "    def _format_finger(self, finger, suffix, bend_angle):\n",
        "        if finger == 'thumb':\n",
        "            return f\"thumb_02_{suffix}(x=0, y=0, z={bend_angle}); thumb_03_{suffix}(x=0, y=0, z={bend_angle})\"\n",
        "        else:\n",
        "            return f\"{finger}_01_{suffix}(x=0, y=0, z={bend_angle}); {finger}_02_{suffix}(x=0, y=0, z={bend_angle}); {finger}_03_{suffix}(x=0, y=0, z={bend_angle})\"\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN DETECTOR\n",
        "# ============================================================================\n",
        "\n",
        "class SignLanguageDetector:\n",
        "    \"\"\"Main detector v·ªõi Motion Retargeting\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.mp_holistic = mp.solutions.holistic\n",
        "        self.holistic = self.mp_holistic.Holistic(\n",
        "            min_detection_confidence=0.3,\n",
        "            min_tracking_confidence=0.3,\n",
        "            model_complexity=1\n",
        "        )\n",
        "        self.detector = GestureDetector()\n",
        "        print(\"‚úÖ SignLanguageDetector V9 (WITH WRIST ORIENTATION) initialized\")\n",
        "\n",
        "    def process_frame(self, frame) -> Tuple[Optional[Dict], Optional[np.ndarray]]:\n",
        "        \"\"\"Process frame and return gesture data + skeleton image\"\"\"\n",
        "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = self.holistic.process(img_rgb)\n",
        "\n",
        "        if not results.pose_landmarks:\n",
        "            return None, None\n",
        "\n",
        "        # Draw skeleton\n",
        "        skeleton_img = self.draw_skeleton(frame, results)\n",
        "\n",
        "        pose_lm = results.pose_landmarks.landmark\n",
        "\n",
        "        # Detect all body parts\n",
        "        output = {}\n",
        "        output.update(self.detector.detect_spine(pose_lm))\n",
        "        output.update(self.detector.detect_head_neck(pose_lm))\n",
        "\n",
        "        # Facial (default values)\n",
        "        output.update({\n",
        "            \"jaw\": \"jaw(z=0)\",\n",
        "            \"eyelid_l\": \"eyelid_l(z=0)\",\n",
        "            \"eyelid_r\": \"eyelid_r(z=0)\",\n",
        "            \"eyes\": \"eye_l(y=0); eye_r(y=0)\",\n",
        "            \"eyebrows\": \"eyebrow_l(z=0); eyebrow_r(z=0)\",\n",
        "            \"mouth_l\": \"mouth_l(x=0, y=0, z=0)\",\n",
        "            \"mouth_r\": \"mouth_r(x=0, y=0, z=0)\"\n",
        "        })\n",
        "\n",
        "        # Arms (with wrist orientation)\n",
        "        output.update(self.detector.detect_arm(pose_lm, results.left_hand_landmarks, 'left'))\n",
        "        output.update(self.detector.detect_arm(pose_lm, results.right_hand_landmarks, 'right'))\n",
        "\n",
        "        return output, skeleton_img\n",
        "\n",
        "    def draw_skeleton(self, frame, results):\n",
        "        \"\"\"Draw skeleton with wrist orientation indicators\"\"\"\n",
        "        mp_drawing = mp.solutions.drawing_utils\n",
        "        mp_drawing_styles = mp.solutions.drawing_styles\n",
        "        mp_holistic = mp.solutions.holistic\n",
        "\n",
        "        annotated = frame.copy()\n",
        "        h, w, _ = annotated.shape\n",
        "\n",
        "        # Draw pose landmarks\n",
        "        if results.pose_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                annotated, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
        "            )\n",
        "\n",
        "        pose_lm = results.pose_landmarks.landmark if results.pose_landmarks else None\n",
        "\n",
        "        # Draw hand landmarks with wrist orientation\n",
        "        if results.right_hand_landmarks and pose_lm:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                annotated, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                mp_drawing_styles.get_default_hand_connections_style()\n",
        "            )\n",
        "\n",
        "            # ‚úÖ V·∫º WRIST ORIENTATION CHO TAY PH·∫¢I\n",
        "            shoulder_r = pose_lm[12]  # Right shoulder\n",
        "            elbow_r = pose_lm[14]     # Right elbow\n",
        "            wrist_r = pose_lm[16]     # Right wrist\n",
        "\n",
        "            wrist_angles = self.detector.calc.calculate_wrist_orientation(\n",
        "                shoulder_r, elbow_r, wrist_r, results.right_hand_landmarks\n",
        "            )\n",
        "            self._draw_wrist_orientation(annotated, wrist_r, w, h, wrist_angles, \"R\")\n",
        "\n",
        "        if results.left_hand_landmarks and pose_lm:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                annotated, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                mp_drawing_styles.get_default_hand_connections_style()\n",
        "            )\n",
        "\n",
        "            # ‚úÖ V·∫º WRIST ORIENTATION CHO TAY TR√ÅI\n",
        "            shoulder_l = pose_lm[11]  # Left shoulder\n",
        "            elbow_l = pose_lm[13]     # Left elbow\n",
        "            wrist_l = pose_lm[15]     # Left wrist\n",
        "\n",
        "            wrist_angles = self.detector.calc.calculate_wrist_orientation(\n",
        "                shoulder_l, elbow_l, wrist_l, results.left_hand_landmarks\n",
        "            )\n",
        "            self._draw_wrist_orientation(annotated, wrist_l, w, h, wrist_angles, \"L\")\n",
        "\n",
        "        return annotated\n",
        "\n",
        "    def _draw_wrist_orientation(self, img, wrist_pose, img_w, img_h, angles, side):\n",
        "        \"\"\"\n",
        "        ‚úÖ V·∫º CH·ªà B√ÅO WRIST ORIENTATION - FIXED\n",
        "\n",
        "        Args:\n",
        "            img: Image to draw on\n",
        "            wrist_pose: Wrist landmark from pose\n",
        "            img_w: Image width\n",
        "            img_h: Image height\n",
        "            angles: Dict v·ªõi pitch, yaw, roll\n",
        "            side: \"L\" ho·∫∑c \"R\"\n",
        "        \"\"\"\n",
        "        cx = int(wrist_pose.x * img_w)\n",
        "        cy = int(wrist_pose.y * img_h)\n",
        "\n",
        "        if cx < 0 or cx >= img_w or cy < 0 or cy >= img_h:\n",
        "            return\n",
        "\n",
        "        # V·∫Ω box hi·ªÉn th·ªã angles\n",
        "        box_width = 120\n",
        "        box_height = 60\n",
        "        box_x = cx - box_width // 2\n",
        "        box_y = cy - 80\n",
        "\n",
        "        # ƒê·∫£m b·∫£o box kh√¥ng v∆∞·ª£t kh·ªèi frame\n",
        "        box_x = max(0, min(box_x, img_w - box_width))\n",
        "        box_y = max(0, min(box_y, img_h - box_height))\n",
        "\n",
        "        # Background\n",
        "        cv2.rectangle(img,\n",
        "                    (box_x, box_y),\n",
        "                    (box_x + box_width, box_y + box_height),\n",
        "                    (0, 0, 0), -1)\n",
        "        cv2.rectangle(img,\n",
        "                    (box_x, box_y),\n",
        "                    (box_x + box_width, box_y + box_height),\n",
        "                    (0, 255, 255), 2)\n",
        "\n",
        "        # Text\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 0.4\n",
        "        thickness = 1\n",
        "\n",
        "        # Title\n",
        "        cv2.putText(img, f\"{side}_Wrist\",\n",
        "                  (box_x + 5, box_y + 15),\n",
        "                  font, font_scale, (0, 255, 255), thickness)\n",
        "\n",
        "        # Angles\n",
        "        cv2.putText(img, f\"P:{angles['pitch']:6.1f}\",\n",
        "                  (box_x + 5, box_y + 30),\n",
        "                  font, font_scale, (255, 255, 255), thickness)\n",
        "        cv2.putText(img, f\"Y:{angles['yaw']:6.1f}\",\n",
        "                  (box_x + 5, box_y + 45),\n",
        "                  font, font_scale, (255, 255, 255), thickness)\n",
        "        cv2.putText(img, f\"R:{angles['roll']:6.1f}\",\n",
        "                  (box_x + 70, box_y + 30),\n",
        "                  font, font_scale, (255, 255, 255), thickness)\n",
        "\n",
        "    def close(self):\n",
        "        self.holistic.close()\n",
        "\n",
        "# ============================================================================\n",
        "# VIDEO PROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def process_video(video_path, output_json=\"gestures_v9.json\", output_dir=\"frames_v9\", frames_per_minute=1):\n",
        "    \"\"\"Process video with V9 Complete (with wrist)\"\"\"\n",
        "\n",
        "    Path(output_dir).mkdir(exist_ok=True)\n",
        "    frames_folder = Path(output_dir) / \"original_frames\"\n",
        "    skeleton_folder = Path(output_dir) / \"skeleton_frames\"\n",
        "    frames_folder.mkdir(exist_ok=True)\n",
        "    skeleton_folder.mkdir(exist_ok=True)\n",
        "\n",
        "    detector = SignLanguageDetector()\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"‚ùå Cannot open video: {video_path}\")\n",
        "        return\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration_sec = total_frames / fps if fps > 0 else 0\n",
        "    frame_interval = int(fps*0.3 / frames_per_minute) if fps > 0 else 1\n",
        "\n",
        "    results = []\n",
        "    frame_id = 0\n",
        "    detected_count = 0\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üé¨ VIDEO: {video_path}\")\n",
        "    print(f\"üìä FPS: {fps:.2f} | Duration: {duration_sec:.1f}s\")\n",
        "    print(f\"‚è±Ô∏è  Sampling: 1 frame every {frame_interval} frames\")\n",
        "    print(f\"üìÅ Output: {output_dir}/\")\n",
        "    print(f\"‚úÖ V9: COMPLETE WITH WRIST ORIENTATION\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_id % frame_interval == 0:\n",
        "            timestamp = frame_id / fps if fps > 0 else frame_id\n",
        "            gesture_data, skeleton_img = detector.process_frame(frame)\n",
        "\n",
        "            if gesture_data and skeleton_img is not None:\n",
        "                frame_filename = f\"frame_{frame_id:06d}_t{timestamp:.2f}s.jpg\"\n",
        "                skeleton_filename = f\"skeleton_{frame_id:06d}_t{timestamp:.2f}s.jpg\"\n",
        "\n",
        "                cv2.imwrite(str(frames_folder / frame_filename), frame)\n",
        "                cv2.imwrite(str(skeleton_folder / skeleton_filename), skeleton_img)\n",
        "\n",
        "                results.append({\n",
        "                    \"frame\": frame_id,\n",
        "                    \"timestamp\": round(timestamp, 3),\n",
        "                    \"original_image\": str(frames_folder / frame_filename),\n",
        "                    \"skeleton_image\": str(skeleton_folder / skeleton_filename),\n",
        "                    \"gestures\": gesture_data\n",
        "                })\n",
        "                detected_count += 1\n",
        "                print(f\"  ‚úÖ Frame {frame_id:6d} at {timestamp:7.2f}s - Detected #{detected_count}\")\n",
        "\n",
        "        frame_id += 1\n",
        "\n",
        "        if frame_id % 300 == 0:\n",
        "            progress = (frame_id / total_frames * 100) if total_frames > 0 else 0\n",
        "            print(f\"  ‚è≥ Progress: {frame_id}/{total_frames} ({progress:.1f}%)\")\n",
        "\n",
        "    cap.release()\n",
        "    detector.close()\n",
        "\n",
        "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"‚úÖ COMPLETED!\")\n",
        "    print(f\"üì¶ Detected: {detected_count} frames\")\n",
        "    print(f\"üíæ JSON: {output_json}\")\n",
        "    print(f\"üñºÔ∏è  Frames: {frames_folder}/ ({detected_count} images)\")\n",
        "    print(f\"ü¶¥ Skeleton: {skeleton_folder}/ ({detected_count} images)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "    import os\n",
        "\n",
        "    VIDEO_PATH = \"D0002.webm\"\n",
        "    OUTPUT_JSON = \"gestures_v9_complete.json\"\n",
        "    OUTPUT_DIR = \"frames_v9_complete\"\n",
        "    FRAMES_PER_MINUTE = 5\n",
        "\n",
        "    if not os.path.exists(VIDEO_PATH):\n",
        "        print(f\"\\n‚ùå ERROR: Video file not found: {VIDEO_PATH}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(f\"\\nüöÄ Starting Sign Language Detection V9 (COMPLETE)\")\n",
        "    print(f\"‚úÖ NEW: Wrist orientation detection (pitch, yaw, roll)\")\n",
        "    print(f\"‚úÖ Full body tracking ho√†n ch·ªânh\")\n",
        "\n",
        "    process_video(VIDEO_PATH, OUTPUT_JSON, OUTPUT_DIR, FRAMES_PER_MINUTE)\n",
        "\n",
        "    print(\"\\nüí° V9 COMPLETE FEATURES:\")\n",
        "    print(\"   ‚úÖ Upper arm: 3-DOF (pitch, yaw, roll)\")\n",
        "    print(\"   ‚úÖ Lower arm: bend + rotation\")\n",
        "    print(\"   ‚úÖ Wrist: 3-DOF (pitch, yaw, roll) ‚Üê M·ªöI!\")\n",
        "    print(\"   ‚úÖ Fingers: individual bend angles\")\n",
        "    print(\"   ‚úÖ Full body: head, neck, spine\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "gyMqJe5qSP7r",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e-sr-NAgWql6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python-headless numpy -q\n",
        "!pip install flask flask-cors pyngrok"
      ],
      "metadata": {
        "id": "8tRYmmCKWruK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall mediapipe -y\n",
        "pip install mediapipe==0.10.14"
      ],
      "metadata": {
        "id": "PLxXQXGestFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import base64\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from math import sqrt, atan2, degrees, acos\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional, Tuple\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# Setup ngrok\n",
        "conf.get_default().auth_token = \"3721EzVULUpY9QkshdRLFveW6LV_2hLJT8sRukP7E4hw6zz6Y\"\n",
        "\n",
        "class RigConfiguration:\n",
        "    def __init__(self):\n",
        "        self.UPPERARM_L = {\n",
        "            \"y\": {\"axis\": \"y\", \"scale\":  1.0, \"offset\": 0},\n",
        "            \"z\": {\"axis\": \"z\", \"scale\":  1.0, \"offset\": 0},\n",
        "            \"x\": {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.UPPERARM_R = {\n",
        "            \"y\": {\"axis\": \"y\", \"scale\":  1.0, \"offset\": 0},\n",
        "            \"z\": {\"axis\": \"z\", \"scale\":  1.0, \"offset\": 0},\n",
        "            \"x\": {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.LOWERARM_L = {\n",
        "            \"bend\":     {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "            \"rotation\": {\"axis\": \"x\", \"scale\":  1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.LOWERARM_R = {\n",
        "            \"bend\":     {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "            \"rotation\": {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.HAND_L = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\":   {\"axis\": \"y\", \"scale\": 0.5, \"offset\": 0},\n",
        "            \"roll\":  {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.HAND_R = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\":   {\"axis\": \"y\", \"scale\": 0.5, \"offset\": 0},\n",
        "            \"roll\":  {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.FINGER_CONFIG = {\"bend\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0}}\n",
        "        self.HEAD  = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\":   {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"roll\":  {\"axis\": \"y\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "        self.NECK  = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 0.5, \"offset\": 0},\n",
        "            \"yaw\":   {\"axis\": \"x\", \"scale\": 0.5, \"offset\": 0}\n",
        "        }\n",
        "        self.SPINE = {\n",
        "            \"pitch\": {\"axis\": \"z\", \"scale\": 1.0, \"offset\": 0},\n",
        "            \"yaw\":   {\"axis\": \"x\", \"scale\": 1.0, \"offset\": 0}\n",
        "        }\n",
        "\n",
        "    def apply_mapping(self, physical_angles: Dict, config: Dict) -> Dict:\n",
        "        result = {\"x\": 0, \"y\": 0, \"z\": 0}\n",
        "        for angle_type, angle_value in physical_angles.items():\n",
        "            if angle_type in config:\n",
        "                m = config[angle_type]\n",
        "                result[m[\"axis\"]] = round(angle_value * m[\"scale\"] + m[\"offset\"], 2)\n",
        "        return result\n",
        "\n",
        "\n",
        "class PhysicalAngleCalculator:\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_elbow_bend(shoulder, elbow, wrist) -> float:\n",
        "        a = np.linalg.norm([elbow.x-shoulder.x, elbow.y-shoulder.y, elbow.z-shoulder.z])\n",
        "        b = np.linalg.norm([wrist.x-elbow.x,    wrist.y-elbow.y,    wrist.z-elbow.z])\n",
        "        c = np.linalg.norm([wrist.x-shoulder.x,  wrist.y-shoulder.y,  wrist.z-shoulder.z])\n",
        "        cos_a = np.clip((a*a + b*b - c*c) / (2*a*b + 1e-6), -1.0, 1.0)\n",
        "        return degrees(acos(cos_a))\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_forearm_rotation(shoulder, elbow, wrist) -> float:\n",
        "        upper = np.array([elbow.x-shoulder.x, elbow.y-shoulder.y, elbow.z-shoulder.z])\n",
        "        upper /= np.linalg.norm(upper) + 1e-6\n",
        "        fore = np.array([wrist.x-elbow.x, wrist.y-elbow.y, wrist.z-elbow.z])\n",
        "        fore /= np.linalg.norm(fore) + 1e-6\n",
        "        perp = fore - np.dot(fore, upper) * upper\n",
        "        perp /= np.linalg.norm(perp) + 1e-6\n",
        "        ref = np.array([0, 1, 0])\n",
        "        ref_p = ref - np.dot(ref, upper) * upper\n",
        "        ref_p /= np.linalg.norm(ref_p) + 1e-6\n",
        "        cos_a = np.clip(np.dot(perp, ref_p), -1.0, 1.0)\n",
        "        rot = degrees(acos(cos_a))\n",
        "        if np.dot(np.cross(ref_p, perp), upper) < 0:\n",
        "            rot = -rot\n",
        "        return round(rot, 2)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_wrist_orientation(shoulder, elbow, wrist, hand_landmarks) -> Dict:\n",
        "        if hand_landmarks is None:\n",
        "            return {\"pitch\": 0.0, \"yaw\": 0.0, \"roll\": 0.0}\n",
        "        wrist_lm   = hand_landmarks.landmark[0]\n",
        "        middle_mcp = hand_landmarks.landmark[9]\n",
        "        dy = middle_mcp.y - wrist_lm.y\n",
        "        pitch = float(np.clip(dy * 60, -45, 90))\n",
        "        return {\"pitch\": round(pitch, 2), \"yaw\": 0.0, \"roll\": 0.0}\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_arm_orientation(shoulder, elbow, wrist=None) -> Dict:\n",
        "        dx = elbow.x - shoulder.x\n",
        "        dy = elbow.y - shoulder.y\n",
        "        dz = elbow.z - shoulder.z\n",
        "        L = sqrt(dx*dx + dy*dy + dz*dz) + 1e-6\n",
        "        dx /= L; dy /= L; dz /= L\n",
        "        yaw   = degrees(atan2(dx, dz))\n",
        "        pitch = degrees(atan2(-dy, sqrt(dx*dx + dz*dz)))\n",
        "        roll  = 0.0\n",
        "        if wrist is not None:\n",
        "            arm = np.array([dx, dy, dz])\n",
        "            wv  = np.array([wrist.x-elbow.x, wrist.y-elbow.y, wrist.z-elbow.z])\n",
        "            perp = wv - np.dot(wv, arm) * arm\n",
        "            perp /= np.linalg.norm(perp) + 1e-6\n",
        "            ref = np.array([0, -1, 0])\n",
        "            ref_p = ref - np.dot(ref, arm) * arm\n",
        "            ref_p /= np.linalg.norm(ref_p) + 1e-6\n",
        "            cos_a = np.clip(np.dot(perp, ref_p), -1.0, 1.0)\n",
        "            roll = degrees(acos(cos_a))\n",
        "            if np.dot(np.cross(ref_p, perp), arm) < 0:\n",
        "                roll = -roll\n",
        "        return {\"x\": round(roll, 2), \"y\": round(yaw, 2), \"z\": round(pitch, 2)}\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_finger_bend(landmarks, finger_ids) -> float:\n",
        "        p1 = landmarks[finger_ids[0]]\n",
        "        p2 = landmarks[finger_ids[1]]\n",
        "        p3 = landmarks[finger_ids[2]]\n",
        "        v1 = np.array([p1.x-p2.x, p1.y-p2.y, p1.z-p2.z])\n",
        "        v2 = np.array([p3.x-p2.x, p3.y-p2.y, p3.z-p2.z])\n",
        "        v1 /= np.linalg.norm(v1) + 1e-6\n",
        "        v2 /= np.linalg.norm(v2) + 1e-6\n",
        "        return round(180 - degrees(acos(np.clip(np.dot(v1, v2), -1.0, 1.0))), 2)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# GESTURE DETECTOR\n",
        "# ============================================================================\n",
        "class GestureDetector:\n",
        "    def __init__(self):\n",
        "        self.calc = PhysicalAngleCalculator()\n",
        "        self.rig  = RigConfiguration()\n",
        "\n",
        "    def detect_arm(self, pose_lm, hand_landmarks, side='left') -> Dict:\n",
        "        if side == 'left':\n",
        "            shoulder, elbow, wrist = pose_lm[11], pose_lm[13], pose_lm[15]\n",
        "            suffix = 'l'\n",
        "            up_cfg, lo_cfg, h_cfg = self.rig.UPPERARM_L, self.rig.LOWERARM_L, self.rig.HAND_L\n",
        "        else:\n",
        "            shoulder, elbow, wrist = pose_lm[12], pose_lm[14], pose_lm[16]\n",
        "            suffix = 'r'\n",
        "            up_cfg, lo_cfg, h_cfg = self.rig.UPPERARM_R, self.rig.LOWERARM_R, self.rig.HAND_R\n",
        "\n",
        "        upperarm_angles = self.calc.calculate_arm_orientation(shoulder, elbow)\n",
        "\n",
        "        if hand_landmarks is None:\n",
        "            elbow_bend = forearm_rotation = 0\n",
        "            wrist_angles = {\"pitch\": 0, \"yaw\": 0, \"roll\": 0}\n",
        "        else:\n",
        "            elbow_bend       = self.calc.calculate_elbow_bend(shoulder, elbow, wrist)\n",
        "            forearm_rotation = self.calc.calculate_forearm_rotation(shoulder, elbow, wrist)\n",
        "            wrist_angles     = self.calc.calculate_wrist_orientation(shoulder, elbow, wrist, hand_landmarks)\n",
        "\n",
        "        up  = self.rig.apply_mapping(upperarm_angles, up_cfg)\n",
        "        lo  = self.rig.apply_mapping({\"bend\": elbow_bend, \"rotation\": forearm_rotation}, lo_cfg)\n",
        "        hnd = self.rig.apply_mapping(wrist_angles, h_cfg)\n",
        "\n",
        "        output = {\n",
        "            f\"shoulder_{suffix}\": f\"shoulder_{suffix}(x=0, y=0, z=0)\",\n",
        "            f\"upperarm_{suffix}\": f\"upperarm_{suffix}(x={up['x']}, y={up['y']}, z={up['z']})\",\n",
        "            f\"lowerarm_{suffix}\": f\"lowerarm_{suffix}(x={lo['x']}, y={lo['y']}, z={lo['z']})\",\n",
        "            f\"hand_{suffix}\":     f\"hand_{suffix}(x={hnd['x']}, y={hnd['y']}, z={hnd['z']})\"\n",
        "        }\n",
        "\n",
        "        if hand_landmarks is None:\n",
        "            for f in ['thumb', 'index', 'middle', 'ring', 'pinky']:\n",
        "                output[f\"{f}_{suffix}\"] = self._default_finger(f, suffix)\n",
        "        else:\n",
        "            lm = hand_landmarks.landmark\n",
        "            FINGERS = {\n",
        "                \"thumb\":  [1, 2, 3, 4],\n",
        "                \"index\":  [5, 6, 7, 8],\n",
        "                \"middle\": [9, 10, 11, 12],\n",
        "                \"ring\":   [13, 14, 15, 16],\n",
        "                \"pinky\":  [17, 18, 19, 20]\n",
        "            }\n",
        "            for fname, ids in FINGERS.items():\n",
        "                bend = self.calc.calculate_finger_bend(lm, ids)\n",
        "                fr   = self.rig.apply_mapping({\"bend\": bend}, self.rig.FINGER_CONFIG)\n",
        "                output[f\"{fname}_{suffix}\"] = self._format_finger(fname, suffix, fr['z'])\n",
        "        return output\n",
        "\n",
        "    def detect_head_neck(self, pose_lm) -> Dict:\n",
        "        return {\"head\": \"head(x=0, y=0, z=0)\", \"neck\": \"neck(x=0, y=0, z=0)\"}\n",
        "\n",
        "    def detect_spine(self, pose_lm) -> Dict:\n",
        "        return {\n",
        "            \"spine_01\": \"spine_01(x=0, y=0, z=0)\",\n",
        "            \"spine_02\": \"spine_02(x=0, y=0, z=0)\",\n",
        "            \"spine_03\": \"spine_03(x=0, y=0, z=0)\"\n",
        "        }\n",
        "\n",
        "    def _default_finger(self, finger, suffix):\n",
        "        if finger == 'thumb':\n",
        "            return f\"thumb_02_{suffix}(x=0, y=0, z=0); thumb_03_{suffix}(x=0, y=0, z=0)\"\n",
        "        return f\"{finger}_01_{suffix}(x=0, y=0, z=0); {finger}_02_{suffix}(x=0, y=0, z=0); {finger}_03_{suffix}(x=0, y=0, z=0)\"\n",
        "\n",
        "    def _format_finger(self, finger, suffix, z):\n",
        "        if finger == 'thumb':\n",
        "            return f\"thumb_02_{suffix}(x=0, y=0, z={z}); thumb_03_{suffix}(x=0, y=0, z={z})\"\n",
        "        return f\"{finger}_01_{suffix}(x=0, y=0, z={z}); {finger}_02_{suffix}(x=0, y=0, z={z}); {finger}_03_{suffix}(x=0, y=0, z={z})\"\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN DETECTOR\n",
        "# ============================================================================\n",
        "class SignLanguageDetector:\n",
        "    def __init__(self):\n",
        "        mp_holistic = mp.solutions.holistic\n",
        "        self.holistic = mp_holistic.Holistic(\n",
        "            min_detection_confidence=0.3,\n",
        "            min_tracking_confidence=0.3,\n",
        "            model_complexity=1\n",
        "        )\n",
        "        self.detector = GestureDetector()\n",
        "        self.calc     = PhysicalAngleCalculator()\n",
        "\n",
        "    def process_frame(self, frame) -> Tuple[Optional[Dict], Optional[np.ndarray]]:\n",
        "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = self.holistic.process(img_rgb)\n",
        "        if not results.pose_landmarks:\n",
        "            return None, None\n",
        "        skeleton_img = self._draw_skeleton(frame, results)\n",
        "        pose_lm = results.pose_landmarks.landmark\n",
        "        output = {}\n",
        "        output.update(self.detector.detect_spine(pose_lm))\n",
        "        output.update(self.detector.detect_head_neck(pose_lm))\n",
        "        output.update({\n",
        "            \"jaw\":      \"jaw(z=0)\",\n",
        "            \"eyelid_l\": \"eyelid_l(z=0)\",\n",
        "            \"eyelid_r\": \"eyelid_r(z=0)\",\n",
        "            \"eyes\":     \"eye_l(y=0); eye_r(y=0)\",\n",
        "            \"eyebrows\": \"eyebrow_l(z=0); eyebrow_r(z=0)\",\n",
        "            \"mouth_l\":  \"mouth_l(x=0, y=0, z=0)\",\n",
        "            \"mouth_r\":  \"mouth_r(x=0, y=0, z=0)\"\n",
        "        })\n",
        "        output.update(self.detector.detect_arm(pose_lm, results.left_hand_landmarks,  'left'))\n",
        "        output.update(self.detector.detect_arm(pose_lm, results.right_hand_landmarks, 'right'))\n",
        "        return output, skeleton_img\n",
        "\n",
        "    def _draw_skeleton(self, frame, results):\n",
        "        mp_drawing        = mp.solutions.drawing_utils\n",
        "        mp_drawing_styles = mp.solutions.drawing_styles\n",
        "        mp_holistic       = mp.solutions.holistic\n",
        "        annotated = frame.copy()\n",
        "        h, w, _   = annotated.shape\n",
        "        if results.pose_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                annotated, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
        "            )\n",
        "        pose_lm = results.pose_landmarks.landmark if results.pose_landmarks else None\n",
        "        for hand_lm, s_idx, e_idx, w_idx, label in [\n",
        "            (results.right_hand_landmarks, 12, 14, 16, 'R'),\n",
        "            (results.left_hand_landmarks,  11, 13, 15, 'L')\n",
        "        ]:\n",
        "            if hand_lm and pose_lm:\n",
        "                mp_drawing.draw_landmarks(\n",
        "                    annotated, hand_lm, mp_holistic.HAND_CONNECTIONS,\n",
        "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                    mp_drawing_styles.get_default_hand_connections_style()\n",
        "                )\n",
        "                angles = self.calc.calculate_wrist_orientation(\n",
        "                    pose_lm[s_idx], pose_lm[e_idx], pose_lm[w_idx], hand_lm\n",
        "                )\n",
        "                self._draw_wrist_info(annotated, pose_lm[w_idx], w, h, angles, label)\n",
        "        return annotated\n",
        "\n",
        "    def _draw_wrist_info(self, img, wrist_pose, img_w, img_h, angles, side):\n",
        "        cx = int(wrist_pose.x * img_w)\n",
        "        cy = int(wrist_pose.y * img_h)\n",
        "        if not (0 <= cx < img_w and 0 <= cy < img_h):\n",
        "            return\n",
        "        bw, bh = 120, 60\n",
        "        bx = max(0, min(cx - bw//2, img_w - bw))\n",
        "        by = max(0, min(cy - 80,    img_h - bh))\n",
        "        cv2.rectangle(img, (bx, by), (bx+bw, by+bh), (0, 0, 0), -1)\n",
        "        cv2.rectangle(img, (bx, by), (bx+bw, by+bh), (0, 255, 255), 2)\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        cv2.putText(img, f\"{side}_Wrist\",            (bx+5, by+15), font, 0.4, (0, 255, 255), 1)\n",
        "        cv2.putText(img, f\"P:{angles['pitch']:6.1f}\", (bx+5, by+30), font, 0.4, (255, 255, 255), 1)\n",
        "        cv2.putText(img, f\"Y:{angles['yaw']:6.1f}\",   (bx+5, by+45), font, 0.4, (255, 255, 255), 1)\n",
        "        cv2.putText(img, f\"R:{angles['roll']:6.1f}\",  (bx+70,by+30), font, 0.4, (255, 255, 255), 1)\n",
        "\n",
        "    def close(self):\n",
        "        self.holistic.close()\n",
        "\n",
        "# ============================================================================\n",
        "# FLASK API\n",
        "# ============================================================================\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "detector = SignLanguageDetector()\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return jsonify({\n",
        "        \"status\": \"API running\",\n",
        "        \"message\": \"Sign Language API ready\"\n",
        "    })\n",
        "\n",
        "@app.route(\"/detect\", methods=[\"POST\"])\n",
        "def detect():\n",
        "\n",
        "    if \"file\" not in request.files:\n",
        "        return jsonify({\"error\": \"No file uploaded\"}), 400\n",
        "\n",
        "    file = request.files[\"file\"]\n",
        "\n",
        "    img_bytes = np.frombuffer(file.read(), np.uint8)\n",
        "    frame = cv2.imdecode(img_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "    if frame is None:\n",
        "        return jsonify({\"error\": \"Invalid image\"}), 400\n",
        "\n",
        "    result, _ = detector.process_frame(frame)\n",
        "\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"data\": result\n",
        "    })\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(\" Public URL:\", public_url)\n",
        "\n",
        "    app.run(host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "id": "Nk-4s3hYWtu5",
        "outputId": "859a4181-34e3-437f-cd0d-fa60a452bb73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Public URL: NgrokTunnel: \"https://lorriane-noncongregative-benson.ngrok-free.dev\" -> \"http://localhost:8000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:8000\n",
            " * Running on http://172.28.0.12:8000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [21/Feb/2026 14:45:27] \"\u001b[31m\u001b[1mGET /detect HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/Feb/2026 14:45:28] \"\u001b[31m\u001b[1mGET /detect HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/Feb/2026 14:46:34] \"\u001b[31m\u001b[1mGET /detect HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/Feb/2026 14:46:43] \"\u001b[31m\u001b[1mGET /detect HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/Feb/2026 14:46:53] \"\u001b[31m\u001b[1mGET /detect HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/Feb/2026 14:46:57] \"\u001b[31m\u001b[1mGET /detect HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/Feb/2026 14:48:02] \"\u001b[31m\u001b[1mGET /detect HTTP/1.1\u001b[0m\" 405 -\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "INFO:werkzeug:127.0.0.1 - - [21/Feb/2026 14:48:12] \"POST /detect HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1W9WKaqBnjI"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import mediapipe as mp\n",
        "# import numpy as np\n",
        "# import json\n",
        "# import os\n",
        "# from math import sqrt, degrees, acos, atan2, asin\n",
        "# from typing import Dict, Optional, Tuple, List\n",
        "\n",
        "# \"\"\"\n",
        "# SIGN LANGUAGE DETECTOR V6 - CUSTOM RIG MAPPING\n",
        "# ==============================================\n",
        "# Gi·∫£i ph√°p: T√°ch bi·ªát vi·ªác t√≠nh to√°n g√≥c v·∫≠t l√Ω v√† vi·ªác map v√†o tr·ª•c Model.\n",
        "# Ng∆∞·ªùi d√πng t·ª± c·∫•u h√¨nh tr·ª•c cho t·ª´ng b·ªô ph·∫≠n trong RIG_CONFIG.\n",
        "\n",
        "# Author: Claude\n",
        "# Date: 2026-01-03\n",
        "# \"\"\"\n",
        "\n",
        "# # ============================================================================\n",
        "# # ‚ö†Ô∏è C·∫§U H√åNH TR·ª§C MODEL C·ª¶A B·∫†N (S·ª¨A ·ªû ƒê√ÇY)\n",
        "# # ============================================================================\n",
        "# # Quy ∆∞·ªõc:\n",
        "# # 'axis': tr·ª•c c·ªßa model ('x', 'y', 'z')\n",
        "# # 'scale': t·ªâ l·ªá v√† h∆∞·ªõng (1.0 l√† c√πng chi·ªÅu, -1.0 l√† ng∆∞·ª£c chi·ªÅu, 0.0 l√† kh√≥a tr·ª•c)\n",
        "# # 'offset': g√≥c c·ªông th√™m (ƒë·ªÉ ch·ªânh pose m·∫∑c ƒë·ªãnh)\n",
        "\n",
        "# RIG_CONFIG = {\n",
        "#     # --- C√ÅNH TAY TR√ÅI ---\n",
        "#     \"left_arm\": {\n",
        "#         # ƒê∆∞a tay ra tr∆∞·ªõc/sau (Flexion/Extension) - B·∫°n n√≥i Z=-90 l√† ra tr∆∞·ªõc\n",
        "#         \"pitch\": {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "#         # Dang tay sang ngang (Abduction) - Th∆∞·ªùng l√† tr·ª•c Y ho·∫∑c X\n",
        "#         \"yaw\":   {\"axis\": \"y\", \"scale\": 1.0,  \"offset\": 80}, # Offset 80 ƒë·ªÉ tay xu√¥i\n",
        "#         # Xoay tr·ª•c tay (Twist)\n",
        "#         \"roll\":  {\"axis\": \"x\", \"scale\": 1.0,  \"offset\": 0},\n",
        "#     },\n",
        "#     \"left_forearm\": {\n",
        "#         # G·∫≠p khu·ª∑u tay (Elbow Flexion) - Th∆∞·ªùng l√† tr·ª•c X ho·∫∑c Z\n",
        "#         \"bend\":  {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "#     },\n",
        "\n",
        "#     # --- C√ÅNH TAY PH·∫¢I (B·∫°n n√≥i chia s·∫ª chung gi√° tr·ªã v·ªõi tr√°i) ---\n",
        "#     \"right_arm\": {\n",
        "#         # ƒê∆∞a tay ra tr∆∞·ªõc (B·∫°n n√≥i gi·ªëng tay tr√°i: Z = -90)\n",
        "#         \"pitch\": {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "#         # Dang tay (Th∆∞·ªùng ng∆∞·ª£c d·∫•u tay tr√°i n·∫øu ƒë·ªëi x·ª©ng, nh∆∞ng b·∫°n check l·∫°i)\n",
        "#         \"yaw\":   {\"axis\": \"y\", \"scale\": -1.0, \"offset\": -80},\n",
        "#         \"roll\":  {\"axis\": \"x\", \"scale\": 1.0,  \"offset\": 0},\n",
        "#     },\n",
        "#     \"right_forearm\": {\n",
        "#         \"bend\":  {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "#     },\n",
        "\n",
        "#     # --- NG√ìN TAY (Th∆∞·ªùng ng√≥n tay g·∫≠p quanh tr·ª•c X ho·∫∑c Z) ---\n",
        "#     # C·∫•u h√¨nh chung cho c√°c ng√≥n (c√≥ th·ªÉ t√°ch ri√™ng n·∫øu c·∫ßn)\n",
        "#     \"fingers\": {\n",
        "#         \"bend_axis\": \"z\",   # Tr·ª•c g·∫≠p ng√≥n tay (S·ª≠a th√†nh 'x' ho·∫∑c 'z' t√πy model)\n",
        "#         \"bend_scale\": 1.0,  # H∆∞·ªõng g·∫≠p\n",
        "#         \"spread_axis\": \"y\"  # Tr·ª•c x√≤e ng√≥n (th∆∞·ªùng √≠t d√πng)\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# # ============================================================================\n",
        "# # LOGIC T√çNH TO√ÅN V·∫¨T L√ù (KH√îNG C·∫¶N S·ª¨A)\n",
        "# # ============================================================================\n",
        "\n",
        "# def calculate_3d_angle(a, b, c):\n",
        "#     \"\"\"T√≠nh g√≥c g·∫≠p gi·ªØa 3 ƒëi·ªÉm trong kh√¥ng gian 3D\"\"\"\n",
        "#     ba = a - b\n",
        "#     bc = c - b\n",
        "#     cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
        "#     angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))\n",
        "#     return angle\n",
        "\n",
        "# def get_elevation_azimuth(p_start, p_end):\n",
        "#     \"\"\"\n",
        "#     T√≠nh g√≥c n√¢ng (Elevation - Pitch) v√† g√≥c ngang (Azimuth - Yaw)\n",
        "#     c·ªßa m·ªôt vector trong h·ªá t·ªça ƒë·ªô chu·∫©n (MediaPipe)\n",
        "#     \"\"\"\n",
        "#     dx = p_end[0] - p_start[0]\n",
        "#     dy = p_end[1] - p_start[1]\n",
        "#     dz = p_end[2] - p_start[2]\n",
        "\n",
        "#     # MediaPipe: Y xu·ªëng (+), X ph·∫£i (+), Z t·ªõi (+)\n",
        "#     # Chuy·ªÉn sang h·ªá quy chi·∫øu ng∆∞·ªùi quan s√°t ƒë·ªÉ d·ªÖ h√¨nh dung:\n",
        "#     # Up/Down (Pitch): D·ª±a v√†o DY\n",
        "#     # Left/Right (Yaw): D·ª±a v√†o DX\n",
        "#     # Front/Back: D·ª±a v√†o DZ\n",
        "\n",
        "#     # T√≠nh Pitch (N√¢ng h·∫°): G√≥c v·ªõi m·∫∑t ph·∫≥ng ngang (XZ)\n",
        "#     # distance_horizontal = sqrt(dx*dx + dz*dz)\n",
        "#     # pitch = degrees(atan2(dy, distance_horizontal)) # -90 (l√™n) ƒë·∫øn 90 (xu·ªëng)\n",
        "\n",
        "#     # ·ªû ƒë√¢y ta d√πng vector ƒë∆°n v·ªã ƒë·ªÉ map v√†o c·∫•u h√¨nh\n",
        "#     v = np.array([dx, dy, dz])\n",
        "#     v = v / (np.linalg.norm(v) + 1e-6)\n",
        "\n",
        "#     # G√≥c Pitch v·∫≠t l√Ω (ƒê∆∞a tay ra tr∆∞·ªõc/sau)\n",
        "#     # Z √¢m l√† ƒë∆∞a ra tr∆∞·ªõc (trong MP Z+ l√† xa camera, Z- l√† g·∫ßn camera?)\n",
        "#     # MP: Z value is depth. Negative is closer to camera.\n",
        "#     # Vector c√°nh tay ƒë∆∞a ra tr∆∞·ªõc: dz s·∫Ω √¢m l·ªõn.\n",
        "#     pitch_physical = np.degrees(np.arctan2(v[2], v[1])) # G√≥c trong m·∫∑t ph·∫≥ng YZ\n",
        "\n",
        "#     # G√≥c Yaw v·∫≠t l√Ω (Dang tay sang ngang)\n",
        "#     yaw_physical = np.degrees(np.arctan2(v[0], v[1]))   # G√≥c trong m·∫∑t ph·∫≥ng XY\n",
        "\n",
        "#     return pitch_physical, yaw_physical\n",
        "\n",
        "# # ============================================================================\n",
        "# # KINEMATIC SOLVER\n",
        "# # ============================================================================\n",
        "\n",
        "# class KinematicSolver:\n",
        "#     def __init__(self):\n",
        "#         pass\n",
        "\n",
        "#     def apply_config(self, phys_val, config_key, part_config):\n",
        "#         \"\"\"Map gi√° tr·ªã v·∫≠t l√Ω v√†o tr·ª•c model d·ª±a tr√™n RIG_CONFIG\"\"\"\n",
        "#         cfg = part_config[config_key]\n",
        "#         axis = cfg['axis']\n",
        "#         scale = cfg['scale']\n",
        "#         offset = cfg['offset']\n",
        "\n",
        "#         mapped_val = (phys_val * scale) + offset\n",
        "#         return axis, int(mapped_val)\n",
        "\n",
        "#     def create_rot_string(self, name, mapping):\n",
        "#         \"\"\"T·∫°o chu·ªói rotation t·ª´ dict mapping {axis: value}\"\"\"\n",
        "#         x = mapping.get('x', 0)\n",
        "#         y = mapping.get('y', 0)\n",
        "#         z = mapping.get('z', 0)\n",
        "#         return f\"{name}(x={x}, y={y}, z={z})\"\n",
        "\n",
        "#     def solve_arm(self, landmarks, side='left'):\n",
        "#         # 1. L·∫•y t·ªça ƒë·ªô landmarks\n",
        "#         if side == 'left':\n",
        "#             sh = np.array([landmarks[11].x, landmarks[11].y, landmarks[11].z])\n",
        "#             el = np.array([landmarks[13].x, landmarks[13].y, landmarks[13].z])\n",
        "#             wr = np.array([landmarks[15].x, landmarks[15].y, landmarks[15].z])\n",
        "#             cfg_name = \"left_arm\"\n",
        "#             fore_name = \"left_forearm\"\n",
        "#             suffix = 'l'\n",
        "#         else:\n",
        "#             sh = np.array([landmarks[12].x, landmarks[12].y, landmarks[12].z])\n",
        "#             el = np.array([landmarks[14].x, landmarks[14].y, landmarks[14].z])\n",
        "#             wr = np.array([landmarks[16].x, landmarks[16].y, landmarks[16].z])\n",
        "#             cfg_name = \"right_arm\"\n",
        "#             fore_name = \"right_forearm\"\n",
        "#             suffix = 'r'\n",
        "\n",
        "#         # 2. T√≠nh to√°n v·∫≠t l√Ω (Physical Calculation)\n",
        "\n",
        "#         # A. B·∫Øp tay (Upper Arm)\n",
        "#         # Vector vai -> khu·ª∑u\n",
        "#         vec_upper = el - sh\n",
        "\n",
        "#         # G√≥c ƒë∆∞a tr∆∞·ªõc/sau (Pitch): D·ª±a tr√™n tr·ª•c Z c·ªßa MP\n",
        "#         # Khi tay xu√¥i (Y+), ƒë∆∞a ra tr∆∞·ªõc (Z-).\n",
        "#         # Ta c·∫ßn t√≠nh ƒë·ªô m·ªü g√≥c so v·ªõi tr·ª•c d·ªçc c∆° th·ªÉ.\n",
        "#         # atan2(z, y): 0 l√† xu√¥i, -90 l√† ƒë∆∞a th·∫≥ng ra tr∆∞·ªõc.\n",
        "#         pitch_phys = np.degrees(np.arctan2(vec_upper[2], vec_upper[1]))\n",
        "\n",
        "#         # G√≥c dang ngang (Yaw): D·ª±a tr√™n tr·ª•c X c·ªßa MP\n",
        "#         # atan2(x, y): 0 l√† xu√¥i, 90 l√† dang ngang.\n",
        "#         yaw_phys = np.degrees(np.arctan2(vec_upper[0], vec_upper[1]))\n",
        "\n",
        "#         # B. C·∫≥ng tay (Forearm)\n",
        "#         # G√≥c g·∫≠p khu·ª∑u tay (lu√¥n d∆∞∆°ng, 180 l√† th·∫≥ng, 90 l√† vu√¥ng)\n",
        "#         elbow_angle = calculate_3d_angle(sh, el, wr)\n",
        "#         # Model th∆∞·ªùng t√≠nh g√≥c g·∫≠p t·ª´ 0 (th·∫≥ng) ƒë·∫øn 90 (vu√¥ng) ho·∫∑c ng∆∞·ª£c l·∫°i\n",
        "#         # Gi·∫£ s·ª≠ model c·ªßa b·∫°n: 0 l√† th·∫≥ng.\n",
        "#         bend_phys = 180 - elbow_angle\n",
        "\n",
        "#         # 3. Mapping v√†o Model (D√πng RIG_CONFIG)\n",
        "#         u_map = {'x': 0, 'y': 0, 'z': 0}\n",
        "#         l_map = {'x': 0, 'y': 0, 'z': 0}\n",
        "\n",
        "#         # Map Upper Arm\n",
        "#         p_axis, p_val = self.apply_config(pitch_phys, 'pitch', RIG_CONFIG[cfg_name])\n",
        "#         y_axis, y_val = self.apply_config(yaw_phys, 'yaw', RIG_CONFIG[cfg_name])\n",
        "\n",
        "#         # C·ªông d·ªìn gi√° tr·ªã v√†o tr·ª•c (v√¨ 1 tr·ª•c c√≥ th·ªÉ ch·ªãu t√°c ƒë·ªông c·ªßa c·∫£ pitch v√† yaw t√πy model)\n",
        "#         u_map[p_axis] += p_val\n",
        "#         u_map[y_axis] += y_val\n",
        "\n",
        "#         # Map Lower Arm\n",
        "#         b_axis, b_val = self.apply_config(bend_phys, 'bend', RIG_CONFIG[fore_name])\n",
        "#         l_map[b_axis] += b_val\n",
        "\n",
        "#         # 4. T·∫°o output string\n",
        "#         upper_str = self.create_rot_string(f\"upperarm_{suffix}\", u_map)\n",
        "#         lower_str = self.create_rot_string(f\"lowerarm_{suffix}\", l_map)\n",
        "\n",
        "#         return {\n",
        "#             f\"upperarm_{suffix}\": upper_str,\n",
        "#             f\"lowerarm_{suffix}\": lower_str,\n",
        "#             f\"shoulder_{suffix}\": f\"shoulder_{suffix}(x=0,y=0,z=0)\", # Vai th∆∞·ªùng √≠t ƒë·ªông\n",
        "#             f\"hand_{suffix}\": f\"hand_{suffix}(x=0,y=0,z=0)\" # T·∫°m th·ªùi ƒë·ªÉ 0\n",
        "#         }\n",
        "\n",
        "#     def solve_fingers(self, landmarks, side='left'):\n",
        "#         # Logic g·∫≠p ng√≥n tay (t√≠nh g√≥c g·∫≠p v√† map v√†o tr·ª•c c·∫•u h√¨nh)\n",
        "#         suffix = 'l' if side == 'left' else 'r'\n",
        "#         fingers_out = {}\n",
        "\n",
        "#         f_indices = {\n",
        "#             'thumb': [1, 2, 3, 4], 'index': [5, 6, 7, 8],\n",
        "#             'middle': [9, 10, 11, 12], 'ring': [13, 14, 15, 16],\n",
        "#             'pinky': [17, 18, 19, 20]\n",
        "#         }\n",
        "\n",
        "#         cfg = RIG_CONFIG['fingers']\n",
        "#         axis = cfg['bend_axis']\n",
        "#         scale = cfg['bend_scale']\n",
        "\n",
        "#         for name, ids in f_indices.items():\n",
        "#             # L·∫•y landmarks\n",
        "#             # Hand landmarks coordinates are relative to wrist usually in MP Hand model,\n",
        "#             # but here we have holistic.\n",
        "\n",
        "#             # T√≠nh g√≥c g·∫≠p trung b√¨nh\n",
        "#             # MCP bend\n",
        "#             angle = calculate_3d_angle(\n",
        "#                 np.array([landmarks[ids[0]].x, landmarks[ids[0]].y, landmarks[ids[0]].z]),\n",
        "#                 np.array([landmarks[ids[1]].x, landmarks[ids[1]].y, landmarks[ids[1]].z]),\n",
        "#                 np.array([landmarks[ids[2]].x, landmarks[ids[2]].y, landmarks[ids[2]].z])\n",
        "#             )\n",
        "\n",
        "#             # 180 l√† th·∫≥ng, 90 l√† g·∫≠p.\n",
        "#             # Model: 0 l√† th·∫≥ng, 90 l√† g·∫≠p (th∆∞·ªùng v·∫≠y)\n",
        "#             bend_val = int((180 - angle) * scale)\n",
        "\n",
        "#             # T·∫°o chu·ªói cho 3 ƒë·ªët (gi·∫£ s·ª≠ g·∫≠p ƒë·ªÅu)\n",
        "#             # Bone names: name_01, name_02, name_03\n",
        "#             f_str = \"\"\n",
        "#             for i in range(1, 4):\n",
        "#                 # Ng√≥n c√°i th∆∞·ªùng ch·ªâ c√≥ 2 ƒë·ªët xoay ch√≠nh ho·∫∑c ƒë·∫∑t t√™n kh√°c, nh∆∞ng theo format c≈© c·ªßa b·∫°n:\n",
        "#                 # thumb_01, thumb_02, thumb_03\n",
        "#                 # V·ªõi ng√≥n c√°i, ƒë·ªët 1 (CMC) √≠t g·∫≠p h∆°n\n",
        "#                 val = bend_val\n",
        "#                 if name == 'thumb' and i == 1: val = int(bend_val * 0.5)\n",
        "\n",
        "#                 f_map = {'x': 0, 'y': 0, 'z': 0}\n",
        "#                 f_map[axis] = val\n",
        "\n",
        "#                 seg_str = self.create_rot_string(f\"{name}_0{i}_{suffix}\", f_map)\n",
        "#                 f_str += seg_str + \"; \"\n",
        "\n",
        "#             fingers_out[name] = f_str.strip(\"; \")\n",
        "\n",
        "#         return fingers_out\n",
        "\n",
        "# # ============================================================================\n",
        "# # MAIN DETECTOR CLASS\n",
        "# # ============================================================================\n",
        "\n",
        "# class SignLanguageDetectorV6:\n",
        "#     def __init__(self):\n",
        "#         self.mp_holistic = mp.solutions.holistic\n",
        "#         self.holistic = self.mp_holistic.Holistic(\n",
        "#             min_detection_confidence=0.5,\n",
        "#             min_tracking_confidence=0.5,\n",
        "#             model_complexity=1\n",
        "#         )\n",
        "#         self.solver = KinematicSolver()\n",
        "#         print(\"‚úÖ SignLanguageDetector V6 (Custom Rig) initialized\")\n",
        "\n",
        "#     def process_frame(self, frame) -> Optional[Dict]:\n",
        "#         img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#         results = self.holistic.process(img_rgb)\n",
        "\n",
        "#         if not results.pose_landmarks: return None\n",
        "#         pose_lm = results.pose_landmarks.landmark\n",
        "\n",
        "#         # Analyze Arms\n",
        "#         left_arm = self.solver.solve_arm(pose_lm, 'left')\n",
        "#         right_arm = self.solver.solve_arm(pose_lm, 'right')\n",
        "\n",
        "#         # Analyze Fingers\n",
        "#         left_fingers = {}\n",
        "#         right_fingers = {}\n",
        "\n",
        "#         if results.right_hand_landmarks: # MP right is person left\n",
        "#             left_fingers = self.solver.solve_fingers(results.right_hand_landmarks.landmark, 'left')\n",
        "\n",
        "#         if results.left_hand_landmarks:\n",
        "#             right_fingers = self.solver.solve_fingers(results.left_hand_landmarks.landmark, 'right')\n",
        "\n",
        "#         # Combine Output\n",
        "#         output = {\n",
        "#             \"spine\": {\"spine_01\": \"spine_01(x=0,y=0,z=0)\"}, # Default\n",
        "#             \"facial\": {}, # Default\n",
        "#             **left_arm,\n",
        "#             **right_arm,\n",
        "#             \"left_hand_fingers\": left_fingers, # Structure slightly adjusted for clarity, you can flatten if needed\n",
        "#             \"right_hand_fingers\": right_fingers\n",
        "#         }\n",
        "\n",
        "#         # Merge fingers back to arm dict structure if needed by Android app\n",
        "#         # (Assuming Android app expects fingers inside left_arm dict)\n",
        "#         output[\"left_arm\"][\"fingers\"] = left_fingers\n",
        "#         output[\"right_arm\"][\"fingers\"] = right_fingers\n",
        "\n",
        "#         # Clean up flat keys if structure requires nesting\n",
        "#         # Based on previous JSON: left_arm contains fingers.\n",
        "\n",
        "#         final_output = {\n",
        "#             \"spine\": {\"spine_01\": \"spine_01(x=0,y=0,z=0)\"},\n",
        "#             \"facial\": {\"jaw\": \"jaw(z=0)\"}, # Minimal defaults\n",
        "#             \"left_arm\": {\n",
        "#                 **left_arm,\n",
        "#                 \"fingers\": left_fingers\n",
        "#             },\n",
        "#             \"right_arm\": {\n",
        "#                 **right_arm,\n",
        "#                 \"fingers\": right_fingers\n",
        "#             }\n",
        "#         }\n",
        "\n",
        "#         return final_output\n",
        "\n",
        "#     def close(self):\n",
        "#         self.holistic.close()\n",
        "\n",
        "# # ============================================================================\n",
        "# # RUNNER\n",
        "# # ============================================================================\n",
        "\n",
        "# def process_video(video_path, output_json, frames_per_minute=60):\n",
        "#     detector = SignLanguageDetectorV6()\n",
        "#     cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "#     if not cap.isOpened():\n",
        "#         print(\"Error opening video\")\n",
        "#         return\n",
        "\n",
        "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "#     frame_interval = int((fps * 60) / frames_per_minute) if frames_per_minute > 0 else 1\n",
        "\n",
        "#     results = []\n",
        "#     frame_id = 0\n",
        "\n",
        "#     while cap.isOpened():\n",
        "#         ret, frame = cap.read()\n",
        "#         if not ret: break\n",
        "\n",
        "#         if frame_id % frame_interval == 0:\n",
        "#             data = detector.process_frame(frame)\n",
        "#             if data:\n",
        "#                 results.append({\n",
        "#                     \"frame\": frame_id,\n",
        "#                     \"timestamp\": round(frame_id/fps, 3),\n",
        "#                     \"gestures\": data\n",
        "#                 })\n",
        "#                 if frame_id % 100 == 0: print(f\"Processed frame {frame_id}\")\n",
        "\n",
        "#         frame_id += 1\n",
        "\n",
        "#     cap.release()\n",
        "#     detector.close()\n",
        "\n",
        "#     with open(output_json, 'w') as f:\n",
        "#         json.dump(results, f, indent=2)\n",
        "#     print(f\"Done. Saved to {output_json}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     VIDEO = \"test_video.webm\"\n",
        "#     if os.path.exists(VIDEO):\n",
        "#         process_video(VIDEO, \"gestures_v6_custom.json\")\n",
        "#     else:\n",
        "#         print(\"Video not found\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## chuy·ªÉn file sang HTTP\n",
        "# import cv2\n",
        "# import mediapipe as mp\n",
        "# import numpy as np\n",
        "# import json\n",
        "# import os\n",
        "# from math import sqrt, degrees, acos, atan2, asin\n",
        "# from typing import Dict, Optional, Tuple, List\n",
        "\n",
        "# \"\"\"\n",
        "# SIGN LANGUAGE DETECTOR V6 - CUSTOM RIG MAPPING\n",
        "# ==============================================\n",
        "# Gi·∫£i ph√°p: T√°ch bi·ªát vi·ªác t√≠nh to√°n g√≥c v·∫≠t l√Ω v√† vi·ªác map v√†o tr·ª•c Model.\n",
        "# Ng∆∞·ªùi d√πng t·ª± c·∫•u h√¨nh tr·ª•c cho t·ª´ng b·ªô ph·∫≠n trong RIG_CONFIG.\n",
        "\n",
        "# Author: Claude\n",
        "# Date: 2026-01-03\n",
        "# \"\"\"\n",
        "\n",
        "# # ============================================================================\n",
        "# # ‚ö†Ô∏è C·∫§U H√åNH TR·ª§C MODEL C·ª¶A B·∫†N (S·ª¨A ·ªû ƒê√ÇY)\n",
        "# # ============================================================================\n",
        "# # Quy ∆∞·ªõc:\n",
        "# # 'axis': tr·ª•c c·ªßa model ('x', 'y', 'z')\n",
        "# # 'scale': t·ªâ l·ªá v√† h∆∞·ªõng (1.0 l√† c√πng chi·ªÅu, -1.0 l√† ng∆∞·ª£c chi·ªÅu, 0.0 l√† kh√≥a tr·ª•c)\n",
        "# # 'offset': g√≥c c·ªông th√™m (ƒë·ªÉ ch·ªânh pose m·∫∑c ƒë·ªãnh)\n",
        "\n",
        "# RIG_CONFIG = {\n",
        "#     # --- C√ÅNH TAY TR√ÅI ---\n",
        "#     \"left_arm\": {\n",
        "#         # ƒê∆∞a tay ra tr∆∞·ªõc/sau (Flexion/Extension) - B·∫°n n√≥i Z=-90 l√† ra tr∆∞·ªõc\n",
        "#         \"pitch\": {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "#         # Dang tay sang ngang (Abduction) - Th∆∞·ªùng l√† tr·ª•c Y ho·∫∑c X\n",
        "#         \"yaw\":   {\"axis\": \"y\", \"scale\": 1.0,  \"offset\": 80}, # Offset 80 ƒë·ªÉ tay xu√¥i\n",
        "#         # Xoay tr·ª•c tay (Twist)\n",
        "#         \"roll\":  {\"axis\": \"x\", \"scale\": 1.0,  \"offset\": 0},\n",
        "#     },\n",
        "#     \"left_forearm\": {\n",
        "#         # G·∫≠p khu·ª∑u tay (Elbow Flexion) - Th∆∞·ªùng l√† tr·ª•c X ho·∫∑c Z\n",
        "#         \"bend\":  {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "#     },\n",
        "\n",
        "#     # --- C√ÅNH TAY PH·∫¢I (B·∫°n n√≥i chia s·∫ª chung gi√° tr·ªã v·ªõi tr√°i) ---\n",
        "#     \"right_arm\": {\n",
        "#         # ƒê∆∞a tay ra tr∆∞·ªõc (B·∫°n n√≥i gi·ªëng tay tr√°i: Z = -90)\n",
        "#         \"pitch\": {\"axis\": \"z\", \"scale\": -1.0, \"offset\": 0},\n",
        "#         # Dang tay (Th∆∞·ªùng ng∆∞·ª£c d·∫•u tay tr√°i n·∫øu ƒë·ªëi x·ª©ng, nh∆∞ng b·∫°n check l·∫°i)\n",
        "#         \"yaw\":   {\"axis\": \"y\", \"scale\": -1.0, \"offset\": -80},\n",
        "#         \"roll\":  {\"axis\": \"x\", \"scale\": 1.0,  \"offset\": 0},\n",
        "#     },\n",
        "#     \"right_forearm\": {\n",
        "#         \"bend\":  {\"axis\": \"x\", \"scale\": -1.0, \"offset\": 0}\n",
        "#     },\n",
        "\n",
        "#     # --- NG√ìN TAY (Th∆∞·ªùng ng√≥n tay g·∫≠p quanh tr·ª•c X ho·∫∑c Z) ---\n",
        "#     # C·∫•u h√¨nh chung cho c√°c ng√≥n (c√≥ th·ªÉ t√°ch ri√™ng n·∫øu c·∫ßn)\n",
        "#     \"fingers\": {\n",
        "#         \"bend_axis\": \"z\",   # Tr·ª•c g·∫≠p ng√≥n tay (S·ª≠a th√†nh 'x' ho·∫∑c 'z' t√πy model)\n",
        "#         \"bend_scale\": 1.0,  # H∆∞·ªõng g·∫≠p\n",
        "#         \"spread_axis\": \"y\"  # Tr·ª•c x√≤e ng√≥n (th∆∞·ªùng √≠t d√πng)\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# # ============================================================================\n",
        "# # LOGIC T√çNH TO√ÅN V·∫¨T L√ù (KH√îNG C·∫¶N S·ª¨A)\n",
        "# # ============================================================================\n",
        "\n",
        "# def calculate_3d_angle(a, b, c):\n",
        "#     \"\"\"T√≠nh g√≥c g·∫≠p gi·ªØa 3 ƒëi·ªÉm trong kh√¥ng gian 3D\"\"\"\n",
        "#     ba = a - b\n",
        "#     bc = c - b\n",
        "#     cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
        "#     angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))\n",
        "#     return angle\n",
        "\n",
        "# def get_elevation_azimuth(p_start, p_end):\n",
        "#     \"\"\"\n",
        "#     T√≠nh g√≥c n√¢ng (Elevation - Pitch) v√† g√≥c ngang (Azimuth - Yaw)\n",
        "#     c·ªßa m·ªôt vector trong h·ªá t·ªça ƒë·ªô chu·∫©n (MediaPipe)\n",
        "#     \"\"\"\n",
        "#     dx = p_end[0] - p_start[0]\n",
        "#     dy = p_end[1] - p_start[1]\n",
        "#     dz = p_end[2] - p_start[2]\n",
        "\n",
        "#     # MediaPipe: Y xu·ªëng (+), X ph·∫£i (+), Z t·ªõi (+)\n",
        "#     # Chuy·ªÉn sang h·ªá quy chi·∫øu ng∆∞·ªùi quan s√°t ƒë·ªÉ d·ªÖ h√¨nh dung:\n",
        "#     # Up/Down (Pitch): D·ª±a v√†o DY\n",
        "#     # Left/Right (Yaw): D·ª±a v√†o DX\n",
        "#     # Front/Back: D·ª±a v√†o DZ\n",
        "\n",
        "#     # T√≠nh Pitch (N√¢ng h·∫°): G√≥c v·ªõi m·∫∑t ph·∫≥ng ngang (XZ)\n",
        "#     # distance_horizontal = sqrt(dx*dx + dz*dz)\n",
        "#     # pitch = degrees(atan2(dy, distance_horizontal)) # -90 (l√™n) ƒë·∫øn 90 (xu·ªëng)\n",
        "\n",
        "#     # ·ªû ƒë√¢y ta d√πng vector ƒë∆°n v·ªã ƒë·ªÉ map v√†o c·∫•u h√¨nh\n",
        "#     v = np.array([dx, dy, dz])\n",
        "#     v = v / (np.linalg.norm(v) + 1e-6)\n",
        "\n",
        "#     # G√≥c Pitch v·∫≠t l√Ω (ƒê∆∞a tay ra tr∆∞·ªõc/sau)\n",
        "#     # Z √¢m l√† ƒë∆∞a ra tr∆∞·ªõc (trong MP Z+ l√† xa camera, Z- l√† g·∫ßn camera?)\n",
        "#     # MP: Z value is depth. Negative is closer to camera.\n",
        "#     # Vector c√°nh tay ƒë∆∞a ra tr∆∞·ªõc: dz s·∫Ω √¢m l·ªõn.\n",
        "#     pitch_physical = np.degrees(np.arctan2(v[2], v[1])) # G√≥c trong m·∫∑t ph·∫≥ng YZ\n",
        "\n",
        "#     # G√≥c Yaw v·∫≠t l√Ω (Dang tay sang ngang)\n",
        "#     yaw_physical = np.degrees(np.arctan2(v[0], v[1]))   # G√≥c trong m·∫∑t ph·∫≥ng XY\n",
        "\n",
        "#     return pitch_physical, yaw_physical\n",
        "\n",
        "# # ============================================================================\n",
        "# # KINEMATIC SOLVER\n",
        "# # ============================================================================\n",
        "\n",
        "# class KinematicSolver:\n",
        "#     def __init__(self):\n",
        "#         pass\n",
        "\n",
        "#     def apply_config(self, phys_val, config_key, part_config):\n",
        "#         \"\"\"Map gi√° tr·ªã v·∫≠t l√Ω v√†o tr·ª•c model d·ª±a tr√™n RIG_CONFIG\"\"\"\n",
        "#         cfg = part_config[config_key]\n",
        "#         axis = cfg['axis']\n",
        "#         scale = cfg['scale']\n",
        "#         offset = cfg['offset']\n",
        "\n",
        "#         mapped_val = (phys_val * scale) + offset\n",
        "#         return axis, int(mapped_val)\n",
        "\n",
        "#     def create_rot_string(self, name, mapping):\n",
        "#         \"\"\"T·∫°o chu·ªói rotation t·ª´ dict mapping {axis: value}\"\"\"\n",
        "#         x = mapping.get('x', 0)\n",
        "#         y = mapping.get('y', 0)\n",
        "#         z = mapping.get('z', 0)\n",
        "#         return f\"{name}(x={x}, y={y}, z={z})\"\n",
        "\n",
        "#     def solve_arm(self, landmarks, side='left'):\n",
        "#         # 1. L·∫•y t·ªça ƒë·ªô landmarks\n",
        "#         if side == 'left':\n",
        "#             sh = np.array([landmarks[11].x, landmarks[11].y, landmarks[11].z])\n",
        "#             el = np.array([landmarks[13].x, landmarks[13].y, landmarks[13].z])\n",
        "#             wr = np.array([landmarks[15].x, landmarks[15].y, landmarks[15].z])\n",
        "#             cfg_name = \"left_arm\"\n",
        "#             fore_name = \"left_forearm\"\n",
        "#             suffix = 'l'\n",
        "#         else:\n",
        "#             sh = np.array([landmarks[12].x, landmarks[12].y, landmarks[12].z])\n",
        "#             el = np.array([landmarks[14].x, landmarks[14].y, landmarks[14].z])\n",
        "#             wr = np.array([landmarks[16].x, landmarks[16].y, landmarks[16].z])\n",
        "#             cfg_name = \"right_arm\"\n",
        "#             fore_name = \"right_forearm\"\n",
        "#             suffix = 'r'\n",
        "\n",
        "#         # 2. T√≠nh to√°n v·∫≠t l√Ω (Physical Calculation)\n",
        "\n",
        "#         # A. B·∫Øp tay (Upper Arm)\n",
        "#         # Vector vai -> khu·ª∑u\n",
        "#         vec_upper = el - sh\n",
        "\n",
        "#         # G√≥c ƒë∆∞a tr∆∞·ªõc/sau (Pitch): D·ª±a tr√™n tr·ª•c Z c·ªßa MP\n",
        "#         # Khi tay xu√¥i (Y+), ƒë∆∞a ra tr∆∞·ªõc (Z-).\n",
        "#         # Ta c·∫ßn t√≠nh ƒë·ªô m·ªü g√≥c so v·ªõi tr·ª•c d·ªçc c∆° th·ªÉ.\n",
        "#         # atan2(z, y): 0 l√† xu√¥i, -90 l√† ƒë∆∞a th·∫≥ng ra tr∆∞·ªõc.\n",
        "#         pitch_phys = np.degrees(np.arctan2(vec_upper[2], vec_upper[1]))\n",
        "\n",
        "#         # G√≥c dang ngang (Yaw): D·ª±a tr√™n tr·ª•c X c·ªßa MP\n",
        "#         # atan2(x, y): 0 l√† xu√¥i, 90 l√† dang ngang.\n",
        "#         yaw_phys = np.degrees(np.arctan2(vec_upper[0], vec_upper[1]))\n",
        "\n",
        "#         # B. C·∫≥ng tay (Forearm)\n",
        "#         # G√≥c g·∫≠p khu·ª∑u tay (lu√¥n d∆∞∆°ng, 180 l√† th·∫≥ng, 90 l√† vu√¥ng)\n",
        "#         elbow_angle = calculate_3d_angle(sh, el, wr)\n",
        "#         # Model th∆∞·ªùng t√≠nh g√≥c g·∫≠p t·ª´ 0 (th·∫≥ng) ƒë·∫øn 90 (vu√¥ng) ho·∫∑c ng∆∞·ª£c l·∫°i\n",
        "#         # Gi·∫£ s·ª≠ model c·ªßa b·∫°n: 0 l√† th·∫≥ng.\n",
        "#         bend_phys = 180 - elbow_angle\n",
        "\n",
        "#         # 3. Mapping v√†o Model (D√πng RIG_CONFIG)\n",
        "#         u_map = {'x': 0, 'y': 0, 'z': 0}\n",
        "#         l_map = {'x': 0, 'y': 0, 'z': 0}\n",
        "\n",
        "#         # Map Upper Arm\n",
        "#         p_axis, p_val = self.apply_config(pitch_phys, 'pitch', RIG_CONFIG[cfg_name])\n",
        "#         y_axis, y_val = self.apply_config(yaw_phys, 'yaw', RIG_CONFIG[cfg_name])\n",
        "\n",
        "#         # C·ªông d·ªìn gi√° tr·ªã v√†o tr·ª•c (v√¨ 1 tr·ª•c c√≥ th·ªÉ ch·ªãu t√°c ƒë·ªông c·ªßa c·∫£ pitch v√† yaw t√πy model)\n",
        "#         u_map[p_axis] += p_val\n",
        "#         u_map[y_axis] += y_val\n",
        "\n",
        "#         # Map Lower Arm\n",
        "#         b_axis, b_val = self.apply_config(bend_phys, 'bend', RIG_CONFIG[fore_name])\n",
        "#         l_map[b_axis] += b_val\n",
        "\n",
        "#         # 4. T·∫°o output string\n",
        "#         upper_str = self.create_rot_string(f\"upperarm_{suffix}\", u_map)\n",
        "#         lower_str = self.create_rot_string(f\"lowerarm_{suffix}\", l_map)\n",
        "\n",
        "#         return {\n",
        "#             f\"upperarm_{suffix}\": upper_str,\n",
        "#             f\"lowerarm_{suffix}\": lower_str,\n",
        "#             f\"shoulder_{suffix}\": f\"shoulder_{suffix}(x=0,y=0,z=0)\", # Vai th∆∞·ªùng √≠t ƒë·ªông\n",
        "#             f\"hand_{suffix}\": f\"hand_{suffix}(x=0,y=0,z=0)\" # T·∫°m th·ªùi ƒë·ªÉ 0\n",
        "#         }\n",
        "\n",
        "#     def solve_fingers(self, landmarks, side='left'):\n",
        "#         # Logic g·∫≠p ng√≥n tay (t√≠nh g√≥c g·∫≠p v√† map v√†o tr·ª•c c·∫•u h√¨nh)\n",
        "#         suffix = 'l' if side == 'left' else 'r'\n",
        "#         fingers_out = {}\n",
        "\n",
        "#         f_indices = {\n",
        "#             'thumb': [1, 2, 3, 4], 'index': [5, 6, 7, 8],\n",
        "#             'middle': [9, 10, 11, 12], 'ring': [13, 14, 15, 16],\n",
        "#             'pinky': [17, 18, 19, 20]\n",
        "#         }\n",
        "\n",
        "#         cfg = RIG_CONFIG['fingers']\n",
        "#         axis = cfg['bend_axis']\n",
        "#         scale = cfg['bend_scale']\n",
        "\n",
        "#         for name, ids in f_indices.items():\n",
        "#             # L·∫•y landmarks\n",
        "#             # Hand landmarks coordinates are relative to wrist usually in MP Hand model,\n",
        "#             # but here we have holistic.\n",
        "\n",
        "#             # T√≠nh g√≥c g·∫≠p trung b√¨nh\n",
        "#             # MCP bend\n",
        "#             angle = calculate_3d_angle(\n",
        "#                 np.array([landmarks[ids[0]].x, landmarks[ids[0]].y, landmarks[ids[0]].z]),\n",
        "#                 np.array([landmarks[ids[1]].x, landmarks[ids[1]].y, landmarks[ids[1]].z]),\n",
        "#                 np.array([landmarks[ids[2]].x, landmarks[ids[2]].y, landmarks[ids[2]].z])\n",
        "#             )\n",
        "\n",
        "#             # 180 l√† th·∫≥ng, 90 l√† g·∫≠p.\n",
        "#             # Model: 0 l√† th·∫≥ng, 90 l√† g·∫≠p (th∆∞·ªùng v·∫≠y)\n",
        "#             bend_val = int((180 - angle) * scale)\n",
        "\n",
        "#             # T·∫°o chu·ªói cho 3 ƒë·ªët (gi·∫£ s·ª≠ g·∫≠p ƒë·ªÅu)\n",
        "#             # Bone names: name_01, name_02, name_03\n",
        "#             f_str = \"\"\n",
        "#             for i in range(1, 4):\n",
        "#                 # Ng√≥n c√°i th∆∞·ªùng ch·ªâ c√≥ 2 ƒë·ªët xoay ch√≠nh ho·∫∑c ƒë·∫∑t t√™n kh√°c, nh∆∞ng theo format c≈© c·ªßa b·∫°n:\n",
        "#                 # thumb_01, thumb_02, thumb_03\n",
        "#                 # V·ªõi ng√≥n c√°i, ƒë·ªët 1 (CMC) √≠t g·∫≠p h∆°n\n",
        "#                 val = bend_val\n",
        "#                 if name == 'thumb' and i == 1: val = int(bend_val * 0.5)\n",
        "\n",
        "#                 f_map = {'x': 0, 'y': 0, 'z': 0}\n",
        "#                 f_map[axis] = val\n",
        "\n",
        "#                 seg_str = self.create_rot_string(f\"{name}_0{i}_{suffix}\", f_map)\n",
        "#                 f_str += seg_str + \"; \"\n",
        "\n",
        "#             fingers_out[name] = f_str.strip(\"; \")\n",
        "\n",
        "#         return fingers_out\n",
        "\n",
        "# # ============================================================================\n",
        "# # MAIN DETECTOR CLASS\n",
        "# # ============================================================================\n",
        "\n",
        "# class SignLanguageDetectorV6:\n",
        "#     def __init__(self):\n",
        "#         self.mp_holistic = mp.solutions.holistic\n",
        "#         self.holistic = self.mp_holistic.Holistic(\n",
        "#             min_detection_confidence=0.5,\n",
        "#             min_tracking_confidence=0.5,\n",
        "#             model_complexity=1\n",
        "#         )\n",
        "#         self.solver = KinematicSolver()\n",
        "#         print(\"‚úÖ SignLanguageDetector V6 (Custom Rig) initialized\")\n",
        "\n",
        "#     def process_frame(self, frame) -> Optional[Dict]:\n",
        "#         img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#         results = self.holistic.process(img_rgb)\n",
        "\n",
        "#         if not results.pose_landmarks: return None\n",
        "#         pose_lm = results.pose_landmarks.landmark\n",
        "\n",
        "#         # Analyze Arms\n",
        "#         left_arm = self.solver.solve_arm(pose_lm, 'left')\n",
        "#         right_arm = self.solver.solve_arm(pose_lm, 'right')\n",
        "\n",
        "#         # Analyze Fingers\n",
        "#         left_fingers = {}\n",
        "#         right_fingers = {}\n",
        "\n",
        "#         if results.right_hand_landmarks: # MP right is person left\n",
        "#             left_fingers = self.solver.solve_fingers(results.right_hand_landmarks.landmark, 'left')\n",
        "\n",
        "#         if results.left_hand_landmarks:\n",
        "#             right_fingers = self.solver.solve_fingers(results.left_hand_landmarks.landmark, 'right')\n",
        "\n",
        "#         # Combine Output\n",
        "#         output = {\n",
        "#             \"spine\": {\"spine_01\": \"spine_01(x=0,y=0,z=0)\"}, # Default\n",
        "#             \"facial\": {}, # Default\n",
        "#             **left_arm,\n",
        "#             **right_arm,\n",
        "#             \"left_hand_fingers\": left_fingers, # Structure slightly adjusted for clarity, you can flatten if needed\n",
        "#             \"right_hand_fingers\": right_fingers\n",
        "#         }\n",
        "\n",
        "#         # Merge fingers back to arm dict structure if needed by Android app\n",
        "#         # (Assuming Android app expects fingers inside left_arm dict)\n",
        "#         output[\"left_arm\"][\"fingers\"] = left_fingers\n",
        "#         output[\"right_arm\"][\"fingers\"] = right_fingers\n",
        "\n",
        "#         # Clean up flat keys if structure requires nesting\n",
        "#         # Based on previous JSON: left_arm contains fingers.\n",
        "\n",
        "#         final_output = {\n",
        "#             \"spine\": {\"spine_01\": \"spine_01(x=0,y=0,z=0)\"},\n",
        "#             \"facial\": {\"jaw\": \"jaw(z=0)\"}, # Minimal defaults\n",
        "#             \"left_arm\": {\n",
        "#                 **left_arm,\n",
        "#                 \"fingers\": left_fingers\n",
        "#             },\n",
        "#             \"right_arm\": {\n",
        "#                 **right_arm,\n",
        "#                 \"fingers\": right_fingers\n",
        "#             }\n",
        "#         }\n",
        "\n",
        "#         return final_output\n",
        "\n",
        "#     def close(self):\n",
        "#         self.holistic.close()\n",
        "\n",
        "# # ============================================================================\n",
        "# # RUNNER\n",
        "# # ============================================================================\n",
        "\n",
        "# def process_video(video_path, output_json, frames_per_minute=60):\n",
        "#     detector = SignLanguageDetectorV6()\n",
        "#     cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "#     if not cap.isOpened():\n",
        "#         print(\"Error opening video\")\n",
        "#         return\n",
        "\n",
        "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "#     frame_interval = int((fps * 60) / frames_per_minute) if frames_per_minute > 0 else 1\n",
        "\n",
        "#     results = []\n",
        "#     frame_id = 0\n",
        "\n",
        "#     while cap.isOpened():\n",
        "#         ret, frame = cap.read()\n",
        "#         if not ret: break\n",
        "\n",
        "#         if frame_id % frame_interval == 0:\n",
        "#             data = detector.process_frame(frame)\n",
        "#             if data:\n",
        "#                 results.append({\n",
        "#                     \"frame\": frame_id,\n",
        "#                     \"timestamp\": round(frame_id/fps, 3),\n",
        "#                     \"gestures\": data\n",
        "#                 })\n",
        "#                 if frame_id % 100 == 0: print(f\"Processed frame {frame_id}\")\n",
        "\n",
        "#         frame_id += 1\n",
        "\n",
        "#     cap.release()\n",
        "#     detector.close()\n",
        "\n",
        "#     with open(output_json, 'w') as f:\n",
        "#         json.dump(results, f, indent=2)\n",
        "#     print(f\"Done. Saved to {output_json}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     VIDEO = \"test_video.webm\"\n",
        "#     if os.path.exists(VIDEO):\n",
        "#         process_video(VIDEO, \"gestures_v6_custom.json\")\n",
        "#     else:\n",
        "#         print(\"Video not found\")"
      ],
      "metadata": {
        "id": "UFIBfn6HpDrR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}